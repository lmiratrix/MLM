{
  "hash": "8e8b747163ccf7f60d4f26f610d90573",
  "result": {
    "markdown": "---\ntitle: \"GLMs vs. Transformations\"\nauthor: \"Josh Gilbert\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n::: {.cell}\n\n:::\n\n\nThose of you coming from S40 and S52 may recall that when we have non-linear relationships between X and Y, we can apply a transformation, such as taking the log, to linearize the relationship.\nIn the words of Jimmy Kim, \"with transformations, we use the *machinery of linear regression to model non-linear relationships.*\" If that's the case, then what is Poisson regression about, which deals with log counts?\nThis is a topic that confused me for many years so hopefully I can clear it up here.\n\n## Making and Graphing the Data\n\nLet's start by making some fake data.\nHere's the data-generating function, which has the relationship that a 1-unit increase in `x` will increase the expected count by $e^.5 = 1.65$.\n\n$$\ny = Poisson(e^{0.5x})\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(ggeffects)\n\ntheme_set(theme_classic())\n\nrm(list = ls())\n\ndat <- tibble(\n  x = runif(1000, 0, 5),\n  y = rpois(1000, exp(0.5*x))\n)\n```\n:::\n\n\nIn the graph, we can see that the relationship between x and y is clearly non linear!\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n```\n\n::: {.cell-output-display}\n![](glm_vs_transform_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nLet's plot `log_y + 1` on `x`.\nAmazing!\nThe relationship is basically linear, which suggests that a 1-unit increase in `x` has some multiplicative effect on `y`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x = x, y = log(y + 1))) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n```\n\n::: {.cell-output-display}\n![](glm_vs_transform_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Fitting the Regression Models\n\nLet's use both OLS and Poisson regression to fit the data.\nWe see a few things:\n\n1.  The Poisson model fits drastically better, both in terms of $R^2$ and that the coefficients are close to the data-generating values\n2.  The transformed OLS model understates the slope\n3.  Both models have (seemingly) similar interpretations: a 1-unit increase in `x` causes an $e^\\beta$ increase in `y`. How is this possible?\n\nSo what's going on?\n\nThe answer is that there is a very subtle difference between a transformed OLS regression and a Poisson regression.\nIn transformed OLS, we are modeling the mean of the log of Y, or $E(ln(y|x))$.\nIn Poisson, we're modeling the log of the mean of Y, or $ln(E(y|x))$.\nThese are not equivalent!\nIn essence, Poisson regression is a model for the arithmetic mean, whereas OLS is a model for the geometric mean.\nThis means that when we exponentiate the Poisson model, we can get predicted counts, but this is *not* true of the OLS model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm(log(y + 1) ~ x, dat)\nm2 <- glm(y ~ x, dat, family = poisson)\n\ntab_model(m1, m2,\n          p.style = \"stars\",\n          show.ci = FALSE,\n          show.se = TRUE,\n          digits = 3,\n          transform = NULL,\n          dv.labels = c(\"Log(Y+1)\", \"Poisson\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Log(Y+1)</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Poisson</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Mean</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.375 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.029</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.074 <sup></sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.045</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">x</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.420 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.010</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.516 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.012</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">1000</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">1000</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.631 / 0.631</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.906</td>\n</tr>\n<tr>\n<td colspan=\"5\" style=\"font-style:italic; border-top:double black; text-align:right;\">* p&lt;0.05&nbsp;&nbsp;&nbsp;** p&lt;0.01&nbsp;&nbsp;&nbsp;*** p&lt;0.001</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n## More Intuition: An Example with Means\n\nLet's create a super simple data set, `s`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- c(1, 10, 100)\n```\n:::\n\n\nIt's clearly skewed.\nBut I can still take the mean.\nI could take the arithmetic mean, or the geometric mean.\nThese are clearly different quantities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(s) # arithmetic\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37\n```\n:::\n\n```{.r .cell-code}\nexp(mean(log((s)))) # geometric\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n\nThe idea of Poisson is to take the log of the mean and fit a linear model for that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_mean <- log(mean(s))\nlog_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.610918\n```\n:::\n:::\n\n\nThe idea of transformed OLS is to take the mean of the log and fit a linear model for that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_log <- mean(log(s))\nmean_log\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.302585\n```\n:::\n:::\n\n\nWhen I exponentiate the log of the mean, I get back the original arithmetic mean.\nThis is what Poisson is doing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(log_mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37\n```\n:::\n:::\n\n\nWhen I exponentiate the mean of the log, I get back the original geometric mean.\nThis is what transformed OLS is doing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(mean_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n\n## Further Reading\n\n<https://www.theanalysisfactor.com/the-difference-between-link-functions-and-data-transformations/>\n",
    "supporting": [
      "glm_vs_transform_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}