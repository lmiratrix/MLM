{
  "hash": "1c3a2c6678e0e399af7c5c64bf247b28",
  "result": {
    "markdown": "---\ntitle: \"Pretty ANOVA Tables with `kable`\"\nauthor: \"Luke Miratrix and Josh Gilbert\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n::: {.cell}\n\n:::\n\n\n## R Setup\n\nWe load the `tidyverse` and `knitr`.\nThe `kable` function from `knitr` makes our tables look nice!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(broom)\n```\n:::\n\n\n## Create fake data\n\nWe create a data set called `a` that has 100 observations and specifies our outcome `Y` as a funciton of two uncorrelated variables `A` and `B`\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- tibble( A = rnorm( 100 ),\n            B = rnorm( 100 ),\n            Y = A * 0.2 + B * 0.5 + rnorm( 100, 0, 1 ) )\n```\n:::\n\n\n## Run the Models\n\nWe fit two models, one with `A` and `B`, the other with just `A`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM1 <- lm( Y~ A + B, data = a )\nM2 <- lm( Y ~ A, data = a )\n```\n:::\n\n\n## Comparing the Models\n\nWe use the `anova` function to compare the two models (see also the chapter on Likelihood Ratio tests).\nWe see that `B` improves the model fit significantly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naa = anova( M2, M1 )\naa\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: Y ~ A\nModel 2: Y ~ A + B\n  Res.Df     RSS Df Sum of Sq      F    Pr(>F)    \n1     98 123.025                                  \n2     97  99.586  1    23.439 22.831 6.286e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\naa |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n|term      | df.residual|      rss| df|    sumsq| statistic| p.value|\n|:---------|-----------:|--------:|--:|--------:|---------:|-------:|\n|Y ~ A     |          98| 123.0246| NA|       NA|        NA|      NA|\n|Y ~ A + B |          97|  99.5855|  1| 23.43907|  22.83053| 6.3e-06|\n:::\n:::\n\n\n## Compare to the Significance test on `B`\n\nNote that the p value for `B` is identical to the ANOVA results above.\nWhy bother with ANOVA?\nIt can test more complex hypotheses as well (multiple coefficients, random effects, etc.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM1 |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n|term        |   estimate| std.error|  statistic|   p.value|\n|:-----------|----------:|---------:|----------:|---------:|\n|(Intercept) | -0.1687802| 0.1015666| -1.6617682| 0.0997879|\n|A           |  0.0375182| 0.1022149|  0.3670519| 0.7143798|\n|B           |  0.4489936| 0.0939685|  4.7781303| 0.0000063|\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}