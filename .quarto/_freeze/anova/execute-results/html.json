{
  "hash": "1c3a2c6678e0e399af7c5c64bf247b28",
  "result": {
    "markdown": "---\ntitle: \"Pretty ANOVA Tables with `kable`\"\nauthor: \"Luke Miratrix and Josh Gilbert\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n::: {.cell}\n\n:::\n\n\n## R Setup\n\nWe load the `tidyverse` and `knitr`.\nThe `kable` function from `knitr` makes our tables look nice!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(broom)\n```\n:::\n\n\n## Create fake data\n\nWe create a data set called `a` that has 100 observations and specifies our outcome `Y` as a funciton of two uncorrelated variables `A` and `B`\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- tibble( A = rnorm( 100 ),\n            B = rnorm( 100 ),\n            Y = A * 0.2 + B * 0.5 + rnorm( 100, 0, 1 ) )\n```\n:::\n\n\n## Run the Models\n\nWe fit two models, one with `A` and `B`, the other with just `A`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM1 <- lm( Y~ A + B, data = a )\nM2 <- lm( Y ~ A, data = a )\n```\n:::\n\n\n## Comparing the Models\n\nWe use the `anova` function to compare the two models (see also the chapter on Likelihood Ratio tests).\nWe see that `B` improves the model fit significantly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naa = anova( M2, M1 )\naa\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: Y ~ A\nModel 2: Y ~ A + B\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     98 142.06                                  \n2     97 106.65  1    35.412 32.207 1.438e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\naa |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n|term      | df.residual|      rss| df|    sumsq| statistic| p.value|\n|:---------|-----------:|--------:|--:|--------:|---------:|-------:|\n|Y ~ A     |          98| 142.0635| NA|       NA|        NA|      NA|\n|Y ~ A + B |          97| 106.6515|  1| 35.41201|  32.20739|   1e-07|\n:::\n:::\n\n\n## Compare to the Significance test on `B`\n\nNote that the p value for `B` is identical to the ANOVA results above.\nWhy bother with ANOVA?\nIt can test more complex hypotheses as well (multiple coefficients, random effects, etc.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM1 |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n|term        |  estimate| std.error| statistic|   p.value|\n|:-----------|---------:|---------:|---------:|---------:|\n|(Intercept) | 0.0202265| 0.1071943| 0.1886904| 0.8507297|\n|A           | 0.2362785| 0.1068462| 2.2113894| 0.0293573|\n|B           | 0.6015946| 0.1060050| 5.6751551| 0.0000001|\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}