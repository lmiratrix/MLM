{
  "hash": "18d5bb72bb330064c4b6b6c32e1d3e5c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MLM Assumptions\"\nauthor: \"Luke Miratrix\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n\n\n\n\n\n\nThere are generally two kinds of assumptions we should worry about the most: omitted variable bias, and independence assumptions.\nThe latter of these is one we should always think about, especially with clustered data.\n\nTo learn about the assumptions, read Chapter 9 of R&B, paying attention to their examples and not so much to the mathematical formalism.\nThis chapter has some dense prose, but then moves to specific diagnostics that make what they are talking about much more clear (and it also provides things you can do to check assumptions in your own work).\nAs another source, the *MLM in Plain Language* textbook has some simpler explanations.\nAlso see below for some further notes.\n\n## Omitted variable bias\n\nConsider the following numerical example:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN = 100\ndat = data.frame( X1 = rnorm( N ) )\ndat = mutate( dat, \n              X2 = X1 + rnorm( N ),\n              Y = 3 + 0.5 * X1 + 1.5 * X2 + rnorm( N ) )\n```\n:::\n\n\n\n\n\n\nThe above code makes a dataset with `X2` correlated with `X1`, and a `Y` that is a function of both.\nThe true model here is $$ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_{i} $$with coefficients $\\beta = (3, 0.5, 1.5)$.\n\nWe fit two models, one including both covariates, and one including only one:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM0 = lm( Y ~ 1 + X1 + X2 , data = dat )\nM1 = lm( Y ~ 1 + X1, data = dat )\n```\n:::\n\n\n\n\n\n\nOur results:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(M0, M1, p.style = \"stars\",\n          show.ci = FALSE, show.se = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Y</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Y</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.10 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.95 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.18</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">X1</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.44 <sup>**</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.92 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.16</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">X2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.51 <sup>***</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">100</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">100</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.856 / 0.853</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.584 / 0.580</td>\n</tr>\n<tr>\n<td colspan=\"5\" style=\"font-style:italic; border-top:double black; text-align:right;\">* p&lt;0.05&nbsp;&nbsp;&nbsp;** p&lt;0.01&nbsp;&nbsp;&nbsp;*** p&lt;0.001</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\nNote our coefficient for the kept variable is completely wrong when we omit a correlated variable.\nThis is **omitted variable bias**, and in terms of our assumptions we are in a circumstance where the true residuals in our model are not centered around 0 for all values of `X1`, since they include the `X2` effect which is correlated with `X1`.\nWe can see this graphically by calculating the true residuals for our data (when we do not include X2) and then plotting them vs. X1:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat = mutate( dat, e = Y - 3 - 0.5 * X1 )\nggplot( dat, aes( X1, e ) ) +\n    geom_point() +\n    geom_hline( yintercept = 0 )\n```\n\n::: {.cell-output-display}\n![](reg_assumptions_files/figure-html/unnamed-chunk-4-1.png){width=288}\n:::\n:::\n\n\n\n\n\n\nNote how our residuals (which includes `X2`) are positive for bigger `X1`, due to the correlation of `X1` and `X2`.\nWe do not have independence between X1 and e, or mathematically put $E[ e | X_1 ] \\neq 0$ for some values of $X_1$.\n\nIn math we can write this for our \"no X2\" model:\n\n$$\nY_i = \\beta_0 + \\beta_1 X_{1i} + \\tilde{\\epsilon}_i = \\beta_0 + \\beta_1 X_{1i} + (\\beta_2 X_{2i} + \\epsilon_{i})\n$$\n\nI.e., our *residual* in our model is actually the secret $X_2$ effect and the original residual.\nThis means our $\\tilde{\\epsilon}_i$ are correlated with $X_{1i}$!\n\n*Conclusion:* On one hand, we have the wrong estimate for $\\beta_1$.\nOn the other, the estimate we do get is fine if we view it as the best description of the data.\nIn our model without `X2`, we are getting the best description of our data using the model we fit to it.\nWe just need to remember that the interpretation of our coefficient includes any confounding effect of `X2` on `X1`.\nIn other words, omitted variable bias is usually part of a critique about *causal* claims, not descriptive ones.\n\n## Independence assumptions\n\nThe independence assumptions are key.\nWhen we do not take violations of independence into account, we can be overly confident of our estimates in that our standard errors can be very, very wrong.\n\nGenerally with MLM we should think of these assumptions in terms of how we sampled our data.\nIf we sampled our data by sampling a collection of schools, and then individuals within those schools, then we have two levels.\nWe then need to ask two questions:\n\n(1) Were the schools sampled independently?\n\n(2) Were the students sampled independently within the schools?\n\nIf yes to both, we have met both our independence assumptions!\nWe have met them even if the students are clustered in classes within their schools.\nAs long as we did not sample using those classes (or other clusters), we are ok as our sample of students will be representative of the school they are in.\n\nTo be crystal clear, if some clustering is not part of how units are sampled, then it can be ignored.\nSo if you are sampling kids from a school district at random, and later learn they are in different neighborhoods (or are grouped in some other natural way like households), you do not need to cluster by neighborhood.\nThat said, you might want to model neighborhood as a cluster to investigate how things vary across those clusters.\n\nAnd what about if you sampled at the school level and surveyed all students within each sampled school.\nDo you need to worry about natural clustering such as classrooms in the school?\nIn this case we are *somewhat* ok.\nFirst, we can pretend our students come from some hypothetical larger population of students.\nThis is of course odd if we sampled all in a school, but we can think of this as something like \"we have this collection of students, but we want to understand how much uncertainty we have regarding the students around their school mean if these students are here in some part due to random chance.\" This explanation is admittedly hand-wavy, but it is implicitly done all the time.\nAn important note is this treats the classrooms as fixed aspects of the school: we are estimating an average across the school's classrooms, and thinking of students as sampled, but not the classroom experiences.\n\nThat said, the school intercept might not fully capture complex dependence within the school (e.g., from student spillover within classrooms); to be 100% safe, use cluster robust standard errors as these allow for arbitrary correlation of students within school.\nBy contrast, the random intercept model says student *residuals* are independent within school, meaning the shared school effect captures all the correlation of students.\n\nFor further discussion, see this [blog post/document from the World bank](https://blogs.worldbank.org/impactevaluations/when-should-you-cluster-standard-errors-new-wisdom-econometrics-oracle) which says clustered SEs are *not* necessary (in OLS) unless sampling was conducted at the cluster-level and that econometricians often overuse them.\n\n## Number of clusters needed?\n\nNeeded number of clusters is not reall an assumption per se, but onwards!\n\nHere is a quick FAQ:\n\nQ: Why should you worry if the number of group is small?\n\nA: With few clusters, estimation is hard just like having a small dataset with OLS.\nThe variance parameters in particular are difficult.\nThe standard errors can be wildly off.\n\nQ: When you say \"at least 20\" you mean for the number of j's, right?\n\nA: Yes, number of clusters.\nMostly Harmless Econometrics readers might recall a discussion of 42 clusters (8.2.3), which contributes to this debate of the appropriate number of level two units.\n\n## A note on testing assumptions\n\nIn this class we do not really talk about how to test these assumptions.\nIn general, we usually test with plots, like with classic OLS.\nFor example we can plot a histogram of the residuals and see if they are normally distributed.\nWe can plot them vs. some covariate to check for heteroskedasticity as well.\n\nSimilarly, we can also plot a histogram of empirical bayes estimated random effects to see if they are normally distributed, or plot those against (level 2) covariates to check for heteroskedasticity.\n\nYou can also plot residuals by level two unit to look for heteroskedasticity.\nMake a boxplot for each level two unit and see if they are all the same size (roughly).\n\nSee Raudenbush and Bryk for more discussion of what to check.\n",
    "supporting": [
      "reg_assumptions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}