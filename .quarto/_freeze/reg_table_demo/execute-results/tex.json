{
  "hash": "57339512a4a7cd36bf6033d7e46e3a01",
  "result": {
    "markdown": "---\ntitle: \"Making Regression Tables and More Complete Summary Output\"\nauthor: \"Luke Miratrix\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n\n\n\nThis document demonstrates the different regression table methods, and talks about some weird wrinkles with using them with multilevel modeling.\n\n## The basics of regression tables\n\nFor the basics we quickly illustrate regression tables using a subset of the Making Caring Common dataset, which we will eventually discuss in class.\nThis dataset has a measure of emotional safety (our outcome) and we want to see, in a specific school, if this is predicted by gender and/or grade.\n\nOur data look like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_n( sch1, 6 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  ID    esafe grade gender     disc race_white\n1  1 3.571429     7 Female 1.111111          1\n2  1 4.000000     7   Male 1.000000          0\n3  1 3.714286     6 Female 3.555556          0\n4  1 3.500000     6   Male 1.111111          1\n5  1 4.000000     5   Male 1.000000          1\n6  1 2.428571     7 Female 2.222222          1\n```\n:::\n:::\n\n\n\nWe fit some models:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM_A = lm( esafe ~ grade, data = sch1 )\nM_B = lm( esafe ~ grade + gender, data = sch1 )\nM_C = lm( esafe ~ grade * gender, data = sch1 )\n```\n:::\n\n\n\nOk, we have fit our regression models.\nWe can look at big complex printout of a single model like so:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary( M_C )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = esafe ~ grade * gender, data = sch1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7894 -0.1570  0.1550  0.2662  0.4938 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       4.12733    0.37946  10.877   <2e-16 ***\ngrade            -0.07764    0.05859  -1.325   0.1879    \ngenderMale       -0.72735    0.49762  -1.462   0.1467    \ngrade:genderMale  0.13327    0.07627   1.747   0.0834 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4333 on 108 degrees of freedom\nMultiple R-squared:  0.04914,\tAdjusted R-squared:  0.02273 \nF-statistic: 1.861 on 3 and 108 DF,  p-value: 0.1406\n```\n:::\n:::\n\n\n\nOr we can make *regression tables*.\nThere are two packages, one is `texreg`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( texreg )\nscreenreg(list(M_A, M_B, M_C))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n====================================================\n                  Model 1     Model 2     Model 3   \n----------------------------------------------------\n(Intercept)         3.68 ***    3.62 ***    4.13 ***\n                   (0.25)      (0.25)      (0.38)   \ngrade               0.00        0.00       -0.08    \n                   (0.04)      (0.04)      (0.06)   \ngenderMale                      0.13       -0.73    \n                               (0.08)      (0.50)   \ngrade:genderMale                            0.13    \n                                           (0.08)   \n----------------------------------------------------\nR^2                 0.00        0.02        0.05    \nAdj. R^2           -0.01        0.00        0.02    \nNum. obs.         112         112         112       \n====================================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\n```\n:::\n:::\n\n\n\nAnother is `stargazer`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( stargazer )\nstargazer( M_A, M_B, M_C, header=FALSE, type='text')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n===============================================================================\n                                        Dependent variable:                    \n                    -----------------------------------------------------------\n                                               esafe                           \n                            (1)                 (2)                 (3)        \n-------------------------------------------------------------------------------\ngrade                      0.004               0.001              -0.078       \n                          (0.038)             (0.038)             (0.059)      \n                                                                               \ngenderMale                                     0.130              -0.727       \n                                              (0.083)             (0.498)      \n                                                                               \ngrade:genderMale                                                  0.133*       \n                                                                  (0.076)      \n                                                                               \nConstant                 3.676***            3.624***            4.127***      \n                          (0.249)             (0.250)             (0.379)      \n                                                                               \n-------------------------------------------------------------------------------\nObservations                112                 112                 112        \nR2                        0.0001               0.022               0.049       \nAdjusted R2               -0.009               0.004               0.023       \nResidual Std. Error  0.440 (df = 110)    0.437 (df = 109)    0.433 (df = 108)  \nF Statistic         0.009 (df = 1; 110) 1.241 (df = 2; 109) 1.861 (df = 3; 108)\n===============================================================================\nNote:                                               *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\n\n## Extending to the multilevel model\n\nFor our multilevel examples, we use the Making Caring Common data from Project A, and fit data to the 8th grade students only, but do it for all schools.\nWe have made a High School dummy variable.\n\nOur two models we use for demo purposes have a HS term and no HS term:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodA <- lmer( esafe ~ 1 + (1 | ID), data=dat.g8)\nmodB <- lmer( esafe ~ 1 + HS + (1 | ID), data=dat.g8)\n```\n:::\n\n\n\nIn the next sections we first show how to get better summary output (according to some folks) and then we walk through making regression tables in a bit more detail than above.\n\n## Better summary output for lmer: Getting p-values\n\nThe `lmerTest` package is a way of making R give you more complete output.\nWe are going to load it, and then put the new lmer models into new variables so we can see how the different model fitting packages work with the regression table packages below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( lmerTest )\nmodB.T <- lmer( esafe ~ 1 + HS + (1 | ID), data=dat.g8)\nmodA.T <- lmer( esafe ~ 1 + (1 | ID), data=dat.g8)\n\nsummary( modB.T )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: esafe ~ 1 + HS + (1 | ID)\n   Data: dat.g8\n\nREML criterion at convergence: 2746.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3883 -0.6156  0.2021  0.7628  1.7331 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.04809  0.2193  \n Residual             0.46459  0.6816  \nNumber of obs: 1305, groups:  ID, 26\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)  3.52798    0.08637 29.91033  40.846   <2e-16 ***\nHSTRUE      -0.29480    0.10787 25.77814  -2.733   0.0112 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr)\nHSTRUE -0.801\n```\n:::\n:::\n\n\n\n## The texreg package\n\nThere are two options, one is `screenreg` and the other is `texreg()`.\n\n### screenreg\n\nScreenreg is fine for MLMs.\nIt looks a bit like raw output, but it is clear and clean.\nIt will take models fit using lmer or lmerTest no problem.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscreenreg(list(modA,modB))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n===============================================\n                     Model 1       Model 2     \n-----------------------------------------------\n(Intercept)              3.35 ***      3.53 ***\n                        (0.06)        (0.09)   \nHSTRUE                                -0.29 ** \n                                      (0.11)   \n-----------------------------------------------\nAIC                   2756.78       2754.79    \nBIC                   2772.30       2775.49    \nLog Likelihood       -1375.39      -1373.40    \nNum. obs.             1305          1305       \nNum. groups: ID         26            26       \nVar: ID (Intercept)      0.07          0.05    \nVar: Residual            0.46          0.46    \n===============================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\n```\n:::\n:::\n\n\n\n*Comment:* Note that the number of stars are different for the display vs the summary output!\n(Look at the HS coefficient for example.) Not good, it would seem.\n\nThis is because the $p$-values are calculated using the normal approximation by the screenreg command, and using the $t$-test with approximate degrees of freedom by `lmerTest`.\nThis makes a difference.\nConsider the following, using the $t$ statistics for the HS variable:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2 * pt( -2.733, df=25.77814 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0111831\n```\n:::\n\n```{.r .cell-code}\n2 * pnorm( -2.733 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.006276033\n```\n:::\n:::\n\n\n\nOne is below 0.01, and one is not.\nAn extra star!\n\n### Using texreg and latex\n\nThe `textreg` command is part of the `texreg` package and can be integrated with latex (which you would need to install).\nOnce you do this, when you compile to a pdf, all is well.\nIn the R code chunk you need to include `results=\"asis\"` to get the latex to compile right.\nE.g., \"`r, results=\"asis\"`\" when you declare a code chunk.\n\n\n\n\n```{.r .cell-code}\ntexreg(list(modA,modB), table=FALSE)\n```\n\n\n\\begin{tabular}{l c c}\n\\hline\n & Model 1 & Model 2 \\\\\n\\hline\n(Intercept)         & $3.35^{***}$ & $3.53^{***}$ \\\\\n                    & $(0.06)$     & $(0.09)$     \\\\\nHSTRUE              &              & $-0.29^{**}$ \\\\\n                    &              & $(0.11)$     \\\\\n\\hline\nAIC                 & $2756.78$    & $2754.79$    \\\\\nBIC                 & $2772.30$    & $2775.49$    \\\\\nLog Likelihood      & $-1375.39$   & $-1373.40$   \\\\\nNum. obs.           & $1305$       & $1305$       \\\\\nNum. groups: ID     & $26$         & $26$         \\\\\nVar: ID (Intercept) & $0.07$       & $0.05$       \\\\\nVar: Residual       & $0.46$       & $0.46$       \\\\\n\\hline\n\\multicolumn{3}{l}{\\scriptsize{$^{***}p<0.001$; $^{**}p<0.01$; $^{*}p<0.05$}}\n\\end{tabular}\n\n\n\nNote that the `table=FALSE` puts the table right where you want it, not at some random spot latex things is nice.\nLatex likes to have \"floating tables\" which it puts where there is space.\n\n## Stargazer\n\n\n\n\n```{.r .cell-code}\nlibrary( stargazer )\nstargazer(modA, modB, header=FALSE, type='latex')\n```\n\n\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lcc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \n & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\ \n\\cline{2-3} \n\\\\[-1.8ex] & \\multicolumn{2}{c}{esafe} \\\\ \n\\\\[-1.8ex] & (1) & (2)\\\\ \n\\hline \\\\[-1.8ex] \n HS &  & $-$0.295$^{***}$ \\\\ \n  &  & (0.108) \\\\ \n  & & \\\\ \n Constant & 3.346$^{***}$ & 3.528$^{***}$ \\\\ \n  & (0.059) & (0.086) \\\\ \n  & & \\\\ \n\\hline \\\\[-1.8ex] \nObservations & 1,305 & 1,305 \\\\ \nLog Likelihood & $-$1,375.388 & $-$1,373.397 \\\\ \nAkaike Inf. Crit. & 2,756.775 & 2,754.795 \\\\ \nBayesian Inf. Crit. & 2,772.297 & 2,775.491 \\\\ \n\\hline \n\\hline \\\\[-1.8ex] \n\\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\ \n\\end{tabular} \n\\end{table} \n\n\n\nOne issue is stargazer does not include the random effect variances, so the output is quite limited for multilevel modeling.\nIt also has less stringent conditions for when to put down stars.\nOne star is below 0.10, two is below 0.05, and three is below 0.01.\nThis is quite generous.\nAlso it is using the normal approximation.\n\n### Stargazer with lmerTest\n\nStargazer with lmerTest is a bit fussy.\nThis shows how to make it work if you have loaded the lmerTest package.\nRecall the lmerTest package makes your lmer commands have p-values and whatnot.\nBut this means your new `lmer()` command is not quite the same as the old---and stargazer is expecting the old.\nYou gix this by lying to R, telling it the new thing is the old thing.\nThis basically works.\n\nNow for stargazer, we need to tell it that our models are the right type.\nFirst note:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass( modB )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lmerMod\"\nattr(,\"package\")\n[1] \"lme4\"\n```\n:::\n\n```{.r .cell-code}\nclass( modB.T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lmerModLmerTest\"\nattr(,\"package\")\n[1] \"lmerTest\"\n```\n:::\n:::\n\n\n\nSo we fix as follows:\n\n\n\n\n```{.r .cell-code}\nlibrary( stargazer )\nclass( modB.T ) = \"lmerMod\" \nclass( modA.T ) = \"lmerMod\" \nstargazer(modA.T, modB.T, header=FALSE, type='latex' )\n```\n\n\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lcc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \n & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\ \n\\cline{2-3} \n\\\\[-1.8ex] & \\multicolumn{2}{c}{esafe} \\\\ \n\\\\[-1.8ex] & (1) & (2)\\\\ \n\\hline \\\\[-1.8ex] \n HS &  & $-$0.295$^{***}$ \\\\ \n  &  & (0.108) \\\\ \n  & & \\\\ \n Constant & 3.346$^{***}$ & 3.528$^{***}$ \\\\ \n  & (0.059) & (0.086) \\\\ \n  & & \\\\ \n\\hline \\\\[-1.8ex] \nObservations & 1,305 & 1,305 \\\\ \nLog Likelihood & $-$1,375.388 & $-$1,373.397 \\\\ \nAkaike Inf. Crit. & 2,756.775 & 2,754.795 \\\\ \nBayesian Inf. Crit. & 2,772.297 & 2,775.491 \\\\ \n\\hline \n\\hline \\\\[-1.8ex] \n\\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\ \n\\end{tabular} \n\\end{table} \n",
    "supporting": [
      "reg_table_demo_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}