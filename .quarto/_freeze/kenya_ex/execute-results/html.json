{
  "hash": "2214b8f39a6496737d40846f16838713",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Example of a three-level longitudinal model\"\nauthor: \"Luke Miratrix\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n\n\n\n\nIn this case study, we illustrate fitting a three level model (where we have time variation and then clusters) and then extracting the various components from it.\nThis example is based on a dataset used in Rabe-Hesketh and Skrondal, chapter 8.10, but you don't really need that text.\n\nShoving a lot of things under the rug, in this case study we have five measurements on a collection of kids in Kenya across time. \nWe are interested in the impact of improved nutrition. The children are clustered in schools. This gives a three-level structure, and we are watching kids grow.\nThe schools were treated with different nutrition programs.\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n## Load the data\n\nIn the following we load the data and look at the first few lines.\nLots of variables!  The main ones are id (the identifier of the kid), treatment (the kind of treatment given to the school), schoolid (the identifier of the school), gender (the gender of the kid), and rn (the time variable). \nOur outcome is ravens (Raven's colored progressive matrices assessment).\n \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkenya = read.dta( \"data/kenya.dta\" )\n\n# look at first 9 variables\nhead( kenya[1:9], 3 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id schoolid rn relyear ravens arithmetic vmeaning dstotal age_at_time0\n1  1        2  1   -0.15     15          5       25       6         7.19\n2  1        2  2    0.14     19          7       39       8         7.19\n3  1        2  3    0.46     21          7       33       7         7.19\n```\n\n\n:::\n\n```{.r .cell-code}\n# what times do we have?\ntable( kenya$rn ) #time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  1   2   3   4   5 \n546 546 546 546 546 \n```\n\n\n:::\n\n```{.r .cell-code}\nlength( unique( kenya$id ) )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 546\n```\n\n\n:::\n\n```{.r .cell-code}\nlength( unique( kenya$schoolid) )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n:::\n\n\n\n\n\nWe see we have 546 kids and 12 schools.\n \n \n\n## Plot and prep the data\nWe can look at the data.\n\n\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nggplot( data=kenya, aes( x=rn, y=ravens, group=id )  )+ \n            facet_wrap( ~ gender ) + \n            geom_line( alpha=0.3 )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 114 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](kenya_ex_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n\nor we can wrap by school to clean up our plot:\n\n\n\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nggplot( data=kenya, aes( x=rn, y=ravens, group=id )  )+ \n            facet_wrap( ~ schoolid ) + \n            geom_line( alpha=0.3 )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 114 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](kenya_ex_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\nOr we can look at a sample of 12 individual children:\n\n\n\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nid.sub = sample( unique( kenya$id), 12 )\nken.sub = subset( kenya, id %in% id.sub )\nggplot( data=ken.sub, aes( x=rn, y=ravens, group=id )  )+ \n            facet_wrap( ~ id ) + \n            geom_line( alpha=0.3 )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_line()`: Each group consists of only one observation.\nâ„¹ Do you need to adjust the group aesthetic?\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](kenya_ex_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nWe have lots of noise!  But there is also a trend.\n\nUsing the mosaic package we can easily calculate the progression of marginal means, and again see there is growth over time, on average:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmosaic::favstats( ravens ~ rn, data=kenya )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  rn min Q1 median Q3 max mean   sd   n missing\n1  1   1 16     17 19  28 17.3 2.56 537       9\n2  2   0 16     17 19  28 17.7 2.79 529      17\n3  3   0 16     18 20  30 18.3 3.04 523      23\n4  4   4 17     18 20  30 18.6 2.97 513      33\n5  5   7 17     19 21  31 19.5 3.10 496      50\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe above also shows that we have some missing data, more as the study progresses.\n\nWe drop these missing observations:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkenya = subset( kenya, !is.na( ravens ) & !is.na( rn ) )\n```\n:::\n\n\n\n\n\n\nWe have some treatments, which we order so control is first\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr( kenya$treatment )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Factor w/ 4 levels \"meat\",\"milk\",..: 1 1 1 1 1 4 4 4 4 4 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nlevels( kenya$treatment )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"meat\"    \"milk\"    \"calorie\" \"control\"\n```\n\n\n:::\n\n```{.r .cell-code}\nkenya$treatment = relevel( kenya$treatment, ref = \"control\" )\nlevels( kenya$treatment )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"control\" \"meat\"    \"milk\"    \"calorie\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## The mathematical model\n\nLet's fit a random slope model, letting kids grow over time.\n\n*Level 1:* We have for individual $i$ in school $j$ at time $t$:\n$$ Y_{ijt} = \\beta_{0ij} + \\beta_{1ij} (t-L) + \\epsilon_{ijt} $$\n\n*Level 2:* Each individual has their own growth curve.  Their curve's slope and intercepts varies around the school means:\n$$ \\beta_{0ij} = \\gamma_{00j} + \\gamma_{01} gender_{ij} + u_{0ij} $$\n$$ \\beta_{1ij} = \\gamma_{10j} + \\gamma_{11} gender_{ij} + u_{1ij} $$\nWe also have that $(u_{0ij}, u_{1ij})$ are normally distributed with some 2x2 covariance matrix.\nWe are forcing the impact of gender to be constant across schools, but are allowing girls and boys to grow at different rates.\nThe average growth rate of a school can be different, as represented by the $\\gamma_{10j}$.\n\n*Level 3:* Finally our school mean slope and intercepts are\n$$ \\gamma_{0j} = \\mu_{00} + w_{0i} $$\n$$ \\gamma_{1j} = \\mu_{10} + \\mu_{11} meat_j + \\mu_{12} milk_j + \\mu_{13} calorie_j + w_{1i}  $$\nFor the rate of growth at a school we allow different slopes for different treatments (compared to baseline).  The milk, meat, and calorie are the three different treatments applied.\nDue to random assignment, we do not expect treatment to be related to baseline outcome, so we do not have the treatment in the intercept term--this is rather unstandard and we would typically allow baseline differences to account for random imbalance in the treatment assignment. But we are following the textbook example here.\n\nWe also have that $(w_{0j}, w_{1j})$ are normally distributed with some 2x2 covariance matrix:\n\n$$  \\begin{pmatrix}w_{j0}\\\\\nw_{j1}\n\\end{pmatrix} \\sim N\\left(\\left(\\begin{array}{c}\n0 \\\\\n0\n\\end{array}\\right), \\left[ \n\\begin{array}{cc}\n\\tau_{00} & \\tau_{01} \\\\\n & \\tau_{11} \n\\end{array}\n\\right]\\right) = N\\left(\\left(\\begin{array}{c}\n0 \\\\\n0\n\\end{array}\\right), \\Sigma_{sch} \\right) $$\n\nThe $\\mu_0$ and $\\mu_1$  are the slope and intercept for the overall population growth (this is what defines our marginal model).\n\nWe will use $L = 1$ to center the data at the first time point (so our intercept is expected ravens score at onset of the study).\n\n*Conceptual question:* What would changing $L$ do to our model and the reasoning about not having treatment in the intercept for school?\n\n\n## Fit the model\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( lme4 )\nkenya$rn = kenya$rn - 1 # center by L=1\nM1 = lmer( ravens ~ 1 + rn + gender*rn + treatment:rn + (1+rn|schoolid) + (1+rn|id:schoolid), \n           data=kenya )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n\n```{.r .cell-code}\ndisplay( M1 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlmer(formula = ravens ~ 1 + rn + gender * rn + treatment:rn + \n    (1 + rn | schoolid) + (1 + rn | id:schoolid), data = kenya)\n                    coef.est coef.se\n(Intercept)         17.41     0.19  \nrn                   0.59     0.08  \ngendergirl          -0.30     0.20  \nrn:gendergirl       -0.14     0.08  \nrn:treatmentmeat     0.17     0.09  \nrn:treatmentmilk    -0.13     0.09  \nrn:treatmentcalorie -0.02     0.09  \n\nError terms:\n Groups      Name        Std.Dev. Corr  \n id:schoolid (Intercept) 1.40           \n             rn          0.43     -0.09 \n schoolid    (Intercept) 0.45           \n             rn          0.09     -1.00 \n Residual                2.31           \n---\nnumber of obs: 2598, groups: id:schoolid, 546; schoolid, 12\nAIC = 12545.9, DIC = 12474\ndeviance = 12496.0 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nNow let's connect some pieces:\n\n* $\\mu_{00} = 17.41$ and $\\mu_{11} = 0.59$.  The initial score for boys is 17.4, on average, with an average gain of 0.59 per year for control schools.\n* $\\gamma_{01} = -0.30$ and $\\gamma_{11} = -0.14$, giving estimates that girls score lower and gain slower than boys.\n* The school-level variation in initial expected Raven scores is 0.45 (this is the standard deviation of $w_{0i}$), relatively small compared to the individual variation of 1.40 (this is the standard deviation of $u_{0ij}$). \n* The correlation of the $u_{0ij}$ and $u_{1ij}$ is basically zero (estimated at -0.09).\n* The random effects for school has a covariance matrix $\\Sigma_{sch}$ of \n$$ \\widehat{\\Sigma}_{sch} = \\left[ \n\\begin{array}{cc}\n0.45^2 & 0.45 \\times 0.09 \\times -0.99 \\\\\n. & 0.09^2 \n\\end{array} \n\\right] $$\nThe very negative correlation suggests an extrapolation effect, and that perhaps we could drop the random slope for schools.\n* The treatment effects are estimated as $\\mu_{11}=0.17, \\mu_{12}=-0.13$, and $\\mu_{13}=-0.02$.  \n* P-values for these will not be small, however, as the standard errors are all 0.09.\n\n\nWe could try to look at uncertainty on our parameters using the `confint( M1 )` command, but it turns out that it crashes for this model. This can happen, and our -0.99 correlation gives a hint as to why.  Let's first drop the random slope at the school level and then try:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM1B = lmer( ravens ~ rn + gender*rn + treatment:rn + (1|schoolid) + (1+rn|id:schoolid), \n           data=kenya )\ndisplay( M1B )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlmer(formula = ravens ~ rn + gender * rn + treatment:rn + (1 | \n    schoolid) + (1 + rn | id:schoolid), data = kenya)\n                    coef.est coef.se\n(Intercept)         17.39     0.17  \nrn                   0.57     0.08  \ngendergirl          -0.30     0.20  \nrn:gendergirl       -0.14     0.08  \nrn:treatmentmeat     0.22     0.10  \nrn:treatmentmilk    -0.09     0.10  \nrn:treatmentcalorie  0.02     0.10  \n\nError terms:\n Groups      Name        Std.Dev. Corr  \n id:schoolid (Intercept) 1.42           \n             rn          0.44     -0.11 \n schoolid    (Intercept) 0.33           \n Residual                2.31           \n---\nnumber of obs: 2598, groups: id:schoolid, 546; schoolid, 12\nAIC = 12544.4, DIC = 12478\ndeviance = 12498.9 \n```\n\n\n:::\n\n```{.r .cell-code}\nconfint( M1B )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      2.5 %   97.5 %\n.sig01               1.1657  1.65435\n.sig02              -0.3544  0.32871\n.sig03               0.3075  0.54179\n.sig04               0.0000  0.60033\n.sigma               2.2312  2.39580\n(Intercept)         17.0605 17.71696\nrn                   0.4091  0.72814\ngendergirl          -0.6870  0.09145\nrn:gendergirl       -0.2879  0.00772\nrn:treatmentmeat     0.0164  0.40811\nrn:treatmentmilk    -0.2876  0.09811\nrn:treatmentcalorie -0.1775  0.20453\n```\n\n\n:::\n:::\n\n\n\n\n\nWe then have to puzzle out which confidence interval goes with what. The `.sig01` is the variance of the kid (`id:schoolid`), which we can tell by the range it covers.  Then the next must be correlation, and then the slope.\nThis tells us we have no confidence the school random intercept is away from 0 (`.sig04`).\n\n\n## Some quick plots\nWe can look at the Empirical Bayes intercepts:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschools = data.frame( resid = ranef( M1 )$schoolid$`(Intercept)` )\nkids = data.frame( resid = ranef( M1 )$id$`(Intercept)` )\nresid = data.frame( resid = resid( M1 ) )\nresids = bind_rows( school=schools, child=kids, residual=resid, .id=\"type\" )\nresids$type = factor( resids$type, levels = c(\"school\",\"child\", \"residual\" ) )\n\nggplot( resids, aes( x = type, y = resid ) ) +\n  geom_boxplot() +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](kenya_ex_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nThis shows that the variation in occasion is much larger than kid, which is much larger than school.\n\nWe can calculate all the individual growth curves and plot those:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkenya$predictions = predict( M1 )\nggplot( data=kenya, aes( x=rn, y=predictions, group=id ) ) +\n    facet_wrap( ~ schoolid, labeller = label_both) +\n    geom_line( alpha=0.3 )\n```\n\n::: {.cell-output-display}\n![](kenya_ex_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nGenerally individual curves are estimated to have positive slopes.  The schools visually look quite similar; any school variation is small compared to individual variation.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}