{"title":"Clarification on Fixed Effects and Identification","markdown":{"yaml":{"title":"Clarification on Fixed Effects and Identification","author":"Luke Miratrix","editor":{"markdown":{"wrap":"sentence"}}},"headingText":"The language of \"Fixed Effects\"","containsRefs":false,"markdown":"\n\nThis chapter talks a bit more about fixed effects.\nIt starts with an overview of the language used to talk about them, gives a brief bit about underidentification, and then moves to looking at how we can have fixed effects interacted with other covariates.\nThe final parts connect to in-class discussion of fixed effects; in particular it gives a reflection on the four concept questions from Packet 1.2 (the live session slides).\n\n\nPeople will talk about \"fixed effects\" in (at least) two ways.\nThe first is when you have a dummy variable for each of your clusters, and you are using OLS regression (not multilevel modeling).\nIn this case you are estimating a parameter for each cluster, and we refer to that collection of estimates and parameters that go with these cluster level dummy variables as \"fixed effects\" and the model is a \"fixed effects model.\" The second is when you are using multilevel modeling, such as the following:\n\n`M0 <- lmer(Y ~ 1 + var1 + var2 + var3 + (var1|id), data)`\n\nWhen we fit the above model, we will be estimating a grand intercept, and three coefficients for the three variables.\nCall these $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$.\nWe are also estimating a random intercept and random slope for `var1`, with each group defined by the `id` variable having its own random intercept and slope.\nThese are described by a variance-covariance matrix that we have been describing with $\\tau_{00}, \\tau_{01}, \\tau_{11}$.\n\nNow, the $\\beta$ are the fixed part, or fixed effects, of the model.\nThe $\\tau$ describe the random part or random effects.\nThis is why, in R, we say `fixef(M0)` to get the $\\beta$.\nIf we say `ranef(M0)` we get the Empirical Bayes estimates of the random parts for each cluster.\nIf we say `coef(M0)` R adds all this together to give the sum of the fixed part and random part, for each cluster defined by `id`.\n\nRead Gelman and Hill 12.3 for more on this sticky language.\nG&H do not like \"fixed effects\" as a description because it is so vague.\n\n## Underidentification\n\nIf we fit a model with a dummy variable for each cluster, and a level to variable that does not vary within cluster, we say our model is \"underidentified.\" We say it is underidentified because no matter how much data we have, we will always have an infinite number of parameter values that can describe our model equally well.\nFor example, say our level 2 variable is a dummy variable (e.g., sector).\nThen a model where we add five to the coefficient of the level 2 variable, and subtract five from all of the fixed effects for the clusters with sector=1 will fit our data just as well as one where we don't.\nWe can't tell the difference!\nHence we do not have enough to \"identify\" the parameter values.\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n\n# Libraries so we can do stuff\nlibrary( foreign )\nlibrary( tidyverse )\n\n\n##\n## Loading data and looking at individuals\n##\n\n# read student data\ndat = read.spss( \"data/hsb1.sav\", to.data.frame=TRUE )\nstr( dat )\nhead( dat )\n\nnrow( dat )\n\n\n# This controls the random number generation.\n# This makes it so we all have the same 10 schools\nset.seed( 12345 )\n\n\n\n#### Making a toy dataset of 10  schools ####\n\nsids = unique( dat$id )\nlength( sids )\n\nwinners = sample( sids, 10 )\nwinners\n\nnrow( dat )\ndat.ten = filter( dat, id %in% winners )\nnrow( dat.ten )\n# dat.ten$id = droplevels( dat.ten$id )\ntable( dat.ten$id )\n\n\n```\n\n## Model syntax: removing the main ses term vs not\n\nWe talked about both these two models:\n\n```{r}\nM1 = lm( mathach ~ 0 + ses*id, data=dat.ten )\ncoef( M1 )\n\nM2 = lm( mathach ~ 0 + ses*id - ses, data=dat.ten )\ncoef( M2 )\n```\n\nNote how when we remove ses via `- ses` we gain an extra interaction term of `ses:id1288`.\nIn M1, our `ses` coefficient is our baseline slope of school 1288.\nThe ses interaction terms are *slope changes*.\n\nNote how if we add ses to the changes we get back all the slopes in M2:\n\n```{r}\ncoef( M1 )[12:20] + coef(M1)[[1]]\n```\n\nBottom line: M1 and M2 are exactly the same in what they are describing, they are just parameterized differently.\nAnything we learn from one we could learn from the other.\n\n### Plot our model\n\nTo plot our model we make a dataset of the intercepts and slopes of each school.\nDoing this with M2 is much easier than M1, since the coefficients are exactly what we want:\n\n```{r}\nlines = data.frame( id = names( coef(M2) )[1:10],\n                    inter = coef(M2)[1:10],\n                    slope = coef(M2)[11:20] )\n\n# we need to fix our IDs.  :-(\nlines$id = gsub( \"id\", \"\", lines$id)\nhead( lines )\n```\n\n(The gsub \"substitutes\" (replaces) the string \"id\" with \"\" in all of our ids so we get back to the actual school ids.\nOtherwise we will not be able to connect these data to our raw students as easily.)\n\nWe now plot!\n\n```{r, fig.height=3, fig.width = 6}\nggplot( dat.ten, aes( ses, mathach ) ) +\n    facet_wrap( ~ id, nrow=2 ) +\n    geom_point( size=0.75, alpha=0.5 ) +\n    geom_abline( data=lines, aes( slope=slope, \n                                  intercept=inter ), \n                 col=\"red\", lwd=1 ) +\n    geom_vline( xintercept = 0 )\n```\n\n### What do the intercepts of any of the lines mean?\n\nThe intercepts predict what math achievement a studnet with ses = 0 going to a given school would have.\nFor example, in school 8800, we predict a student with an ses of 0 would have a math achievement of 9.2.\n\nNotice that for some schools the intercept is *extrapolating*.\nE.g., most of school 8800's students are below 0 for ses, and the intercept is thus describing what we expect for students at the higher end of their range.\nFor school 9225, we are seeing a prediction for students a bit below the middle of their range.\n\n```{r, include=FALSE}\ndat.ten %>% group_by( id ) %>% \n    summarise( mean_ses = mean( ses ) )\n```\n\n### What differences, if any, are there between running a new linear model on each school vs. running the interacted model on the set of 10 schools?\n\nThe lines would be *exactly* the same.\nThe standard errors are different.\nHere is the line on just school 1288:\n\n```{r}\ns1288 = filter( dat.ten, id == \"1288\" )\nM_1288 = lm( mathach ~ 1 + ses, data=s1288 )\nsummary( M_1288 )\n```\n\nThe SEs will be different, however.\nCompare:\n\n```{r}\nsum = summary( M2 )\nsum$coefficients[ c(1, 11 ), ]\n```\n\nIn this case the SEs are close, but they could be a lot different if we have a lot of heteroskedasticity or the school has few data points so we do a bad job estimating uncertainty.\n\nThe key is in the single model we are using *all* the schools to estimate the residual variance, and this is the number that drives our SE estimates.\n\n### Do we trust the red lines on the plot? Why or why not?\n\nWe trust them because they are driven just by the school data, so they are essentially unbiased.\nBut these are small datasets, so they are unstable.\n\n### What about the variability in the slopes and intercepts of the red lines?\n\nThe variation is not to be trusted.\nThe slopes are varying because of measurement error.\nFor example, it is unlikely school 3533 really has a negative slope.\nIt is more likely we just got some low performing high ses kids by happenstance in our sample.\nSimilarly, it is unlikely school 6170 has such a steep slope.\nIt has few kids, and the kid with less than -2 ses and a very low math achievment is likely an influential point in that regression.\n\n## Further Reading\n\n[@antonakis2019a]\n","srcMarkdownNoYaml":"\n\nThis chapter talks a bit more about fixed effects.\nIt starts with an overview of the language used to talk about them, gives a brief bit about underidentification, and then moves to looking at how we can have fixed effects interacted with other covariates.\nThe final parts connect to in-class discussion of fixed effects; in particular it gives a reflection on the four concept questions from Packet 1.2 (the live session slides).\n\n## The language of \"Fixed Effects\"\n\nPeople will talk about \"fixed effects\" in (at least) two ways.\nThe first is when you have a dummy variable for each of your clusters, and you are using OLS regression (not multilevel modeling).\nIn this case you are estimating a parameter for each cluster, and we refer to that collection of estimates and parameters that go with these cluster level dummy variables as \"fixed effects\" and the model is a \"fixed effects model.\" The second is when you are using multilevel modeling, such as the following:\n\n`M0 <- lmer(Y ~ 1 + var1 + var2 + var3 + (var1|id), data)`\n\nWhen we fit the above model, we will be estimating a grand intercept, and three coefficients for the three variables.\nCall these $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$.\nWe are also estimating a random intercept and random slope for `var1`, with each group defined by the `id` variable having its own random intercept and slope.\nThese are described by a variance-covariance matrix that we have been describing with $\\tau_{00}, \\tau_{01}, \\tau_{11}$.\n\nNow, the $\\beta$ are the fixed part, or fixed effects, of the model.\nThe $\\tau$ describe the random part or random effects.\nThis is why, in R, we say `fixef(M0)` to get the $\\beta$.\nIf we say `ranef(M0)` we get the Empirical Bayes estimates of the random parts for each cluster.\nIf we say `coef(M0)` R adds all this together to give the sum of the fixed part and random part, for each cluster defined by `id`.\n\nRead Gelman and Hill 12.3 for more on this sticky language.\nG&H do not like \"fixed effects\" as a description because it is so vague.\n\n## Underidentification\n\nIf we fit a model with a dummy variable for each cluster, and a level to variable that does not vary within cluster, we say our model is \"underidentified.\" We say it is underidentified because no matter how much data we have, we will always have an infinite number of parameter values that can describe our model equally well.\nFor example, say our level 2 variable is a dummy variable (e.g., sector).\nThen a model where we add five to the coefficient of the level 2 variable, and subtract five from all of the fixed effects for the clusters with sector=1 will fit our data just as well as one where we don't.\nWe can't tell the difference!\nHence we do not have enough to \"identify\" the parameter values.\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n\n# Libraries so we can do stuff\nlibrary( foreign )\nlibrary( tidyverse )\n\n\n##\n## Loading data and looking at individuals\n##\n\n# read student data\ndat = read.spss( \"data/hsb1.sav\", to.data.frame=TRUE )\nstr( dat )\nhead( dat )\n\nnrow( dat )\n\n\n# This controls the random number generation.\n# This makes it so we all have the same 10 schools\nset.seed( 12345 )\n\n\n\n#### Making a toy dataset of 10  schools ####\n\nsids = unique( dat$id )\nlength( sids )\n\nwinners = sample( sids, 10 )\nwinners\n\nnrow( dat )\ndat.ten = filter( dat, id %in% winners )\nnrow( dat.ten )\n# dat.ten$id = droplevels( dat.ten$id )\ntable( dat.ten$id )\n\n\n```\n\n## Model syntax: removing the main ses term vs not\n\nWe talked about both these two models:\n\n```{r}\nM1 = lm( mathach ~ 0 + ses*id, data=dat.ten )\ncoef( M1 )\n\nM2 = lm( mathach ~ 0 + ses*id - ses, data=dat.ten )\ncoef( M2 )\n```\n\nNote how when we remove ses via `- ses` we gain an extra interaction term of `ses:id1288`.\nIn M1, our `ses` coefficient is our baseline slope of school 1288.\nThe ses interaction terms are *slope changes*.\n\nNote how if we add ses to the changes we get back all the slopes in M2:\n\n```{r}\ncoef( M1 )[12:20] + coef(M1)[[1]]\n```\n\nBottom line: M1 and M2 are exactly the same in what they are describing, they are just parameterized differently.\nAnything we learn from one we could learn from the other.\n\n### Plot our model\n\nTo plot our model we make a dataset of the intercepts and slopes of each school.\nDoing this with M2 is much easier than M1, since the coefficients are exactly what we want:\n\n```{r}\nlines = data.frame( id = names( coef(M2) )[1:10],\n                    inter = coef(M2)[1:10],\n                    slope = coef(M2)[11:20] )\n\n# we need to fix our IDs.  :-(\nlines$id = gsub( \"id\", \"\", lines$id)\nhead( lines )\n```\n\n(The gsub \"substitutes\" (replaces) the string \"id\" with \"\" in all of our ids so we get back to the actual school ids.\nOtherwise we will not be able to connect these data to our raw students as easily.)\n\nWe now plot!\n\n```{r, fig.height=3, fig.width = 6}\nggplot( dat.ten, aes( ses, mathach ) ) +\n    facet_wrap( ~ id, nrow=2 ) +\n    geom_point( size=0.75, alpha=0.5 ) +\n    geom_abline( data=lines, aes( slope=slope, \n                                  intercept=inter ), \n                 col=\"red\", lwd=1 ) +\n    geom_vline( xintercept = 0 )\n```\n\n### What do the intercepts of any of the lines mean?\n\nThe intercepts predict what math achievement a studnet with ses = 0 going to a given school would have.\nFor example, in school 8800, we predict a student with an ses of 0 would have a math achievement of 9.2.\n\nNotice that for some schools the intercept is *extrapolating*.\nE.g., most of school 8800's students are below 0 for ses, and the intercept is thus describing what we expect for students at the higher end of their range.\nFor school 9225, we are seeing a prediction for students a bit below the middle of their range.\n\n```{r, include=FALSE}\ndat.ten %>% group_by( id ) %>% \n    summarise( mean_ses = mean( ses ) )\n```\n\n### What differences, if any, are there between running a new linear model on each school vs. running the interacted model on the set of 10 schools?\n\nThe lines would be *exactly* the same.\nThe standard errors are different.\nHere is the line on just school 1288:\n\n```{r}\ns1288 = filter( dat.ten, id == \"1288\" )\nM_1288 = lm( mathach ~ 1 + ses, data=s1288 )\nsummary( M_1288 )\n```\n\nThe SEs will be different, however.\nCompare:\n\n```{r}\nsum = summary( M2 )\nsum$coefficients[ c(1, 11 ), ]\n```\n\nIn this case the SEs are close, but they could be a lot different if we have a lot of heteroskedasticity or the school has few data points so we do a bad job estimating uncertainty.\n\nThe key is in the single model we are using *all* the schools to estimate the residual variance, and this is the number that drives our SE estimates.\n\n### Do we trust the red lines on the plot? Why or why not?\n\nWe trust them because they are driven just by the school data, so they are essentially unbiased.\nBut these are small datasets, so they are unstable.\n\n### What about the variability in the slopes and intercepts of the red lines?\n\nThe variation is not to be trusted.\nThe slopes are varying because of measurement error.\nFor example, it is unlikely school 3533 really has a negative slope.\nIt is more likely we just got some low performing high ses kids by happenstance in our sample.\nSimilarly, it is unlikely school 6170 has such a steep slope.\nIt has few kids, and the kid with less than -2 ses and a very low math achievment is likely an influential point in that regression.\n\n## Further Reading\n\n[@antonakis2019a]\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"pygments","output-file":"fixed_effects.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"theme":"cosmo","code-copy":true,"title":"Clarification on Fixed Effects and Identification","author":"Luke Miratrix"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"pygments","output-file":"fixed_effects.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"documentclass":"scrreprt","title":"Clarification on Fixed Effects and Identification","author":"Luke Miratrix"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}