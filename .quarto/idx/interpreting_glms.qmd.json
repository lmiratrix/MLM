{"title":"Interpreting GLMs","markdown":{"yaml":{"title":"Interpreting GLMs","author":"Luke Miratrix & Joe McIntyre","editor":{"markdown":{"wrap":"sentence"}}},"headingText":"Poisson regression models","containsRefs":false,"markdown":"\n\n\nPoisson regression is sometimes used to model count data.\nThe canonical form of a Poisson (log-linear) regression model is $$\\log(E[Y|X]) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$ $$Y \\sim Poisson(E[Y|X])$$\n\nThe Poisson distribution has only one parameter, the mean, which is also the variance of the distribution.\nSo in estimating $E[Y|X]$, we are also estimating $Var(Y|X)$.\nThis is a potential drawback to the Poisson model, because there is no variance parameter to estimate, and so incorrect models can give wildly inaccurate standard errors (frequently unrealistically small).\nA better model is a quasi-Poisson model, for which the variance is proportional to the mean, but not necessarily equal to it.\nThe negative binomial regression model is also commonly used to address over-dispersed count data where the variance exceeds the mean.\n\nThe canonical link function for Poisson outcomes is the natural logarithm.\nWhen we use a log-link, we can write\n\n$$E[Y|X] = e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}.$$\n\nWe can interpret $\\beta_0$ as follows: for observations which are 0 on all of the predictors, we estimate that the mean (expected) value of the outcome will be $e^{\\beta_0}$.\n\nWe can interpret $\\beta_1$ as follows: adjusting for the other predictors, a one-unit difference in $X_1$ predicts a $(e^{\\beta_1}-1)\\times100 \\%$ difference in the outcome.\n\nGenerally, when using a log-link, we assume that differences in the predictors are associated with multiplicative differences in the outcome.\n\nSome advantages to using an exponential link are\n\n1.  the model is mathematically more tractable and simpler to fit\n\n2.  the model parameters are easy to interpret\n\n3.  the mean of $Y$ is guaranteed to be positive for all values of $X$, which is required by the Poisson distribution\n\nWe can fit a Poisson log-linear regression by writing\n\nglm(Y $\\sim$ X, family = poisson(link = 'log'))\n\nTo fit a quasi-Poisson model, write\n\nglm(Y $\\sim$ X, family = quasipoisson(link = 'log'))\n\nTo fit a negative binomial regression model, write (after loading the `MASS` library)\n\nglm.nb(Y $\\sim$ X, link='log')\n\nTo fit a Poisson regression with an identity link (where coefficients are interpreted as expected differences in the outcome associated with unit differences in the predictor), write\n\nglm(Y $\\sim$ X, family = poisson(link = 'identity'))\n\nTo fit a Poisson regression with a square root link, which is vaguely like a compromise between an identity link and a log link (and is harder to interpret than either), write\n\nglm(Y $\\sim$ X, family = poisson(link = 'sqrt'))\n\nTo fit a Poisson log-linear model with a random intercept and slope, write\n\nglmer(Y $\\sim$ X + (X\\|grp), family = poisson(link = 'log'))\n\n## Dichotomous regression models\n\nWhen predicting either successes and failures, or proportions, we can use a model with a binomial outcome.\nHere we'll focus on models where the data is represented as individual successes and failures.\nThe canonical model for these data is logistic regression, where\n\n$$logit(E[Y|X]) \\equiv \\log\\left(\\frac{P(Y=1|X)}{1-P(Y=1|X)}\\right) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$ $$Y \\sim Binomial(1, E[Y|X])$$\n\nWe can rewrite this model as\n\n$$odds(Y) = \\frac{P(Y=1|X)}{1-P(Y=1|X)} = e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}$$\n\nor\n\n$$P(Y=1|X) = \\frac{e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}{1 + e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}$$\n\nWe can interpret $\\beta_0$ as follows: for observations which are 0 on all of the predictors, we estimate that the mean value of the outcome will be $\\frac{e^{\\beta_0}}{1 + e^{\\beta_0}}$.\nThat is, we estimate that the probability of the outcome being a 'success' (assuming 'success' is coded as a 1) will be $\\frac{e^{\\beta_0}}{1 + e^{\\beta_0}}$.\n\nWe can interpret $\\beta_1$ as follows: adjusting for the other predictors, a one-unit difference in $X_1$ predicts a $\\beta_1$ difference in the log-odds of the outcome being one, or a $(e^{\\beta_1}-1)\\times100\\%$ difference in the odds of the outcome.\nUnfortunately, the change in probability of a unit change depends on where the starting point is, so there is no easy way to interpret these coefficients in terms of direct probability.\nOne can calculate the estimated change for specific units, however, and look at the distribution of those changes.\n\nOther possible link functions include the probit (which uses a Normal CDF to link $\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$ to $P(Y=1|X)$), or the complementary log-log (which allows $P(Y = 1|X)$ to be asymmetric in the predictors), among others.\n\n### Example\n\n### How to fit a GLM\n\nWe can fit a logistic regression model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'logit'))\n\nWe can fit a probit regression model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'probit'))\n\nWe can fit a complementary log-log model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'cloglog'))\n\nWe can allow a random slope and intercept by writing\n\nglmer(Y $\\sim$ X + (X\\|grp), family = binomial(link = 'logit'))\n","srcMarkdownNoYaml":"\n\n## Poisson regression models\n\nPoisson regression is sometimes used to model count data.\nThe canonical form of a Poisson (log-linear) regression model is $$\\log(E[Y|X]) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$ $$Y \\sim Poisson(E[Y|X])$$\n\nThe Poisson distribution has only one parameter, the mean, which is also the variance of the distribution.\nSo in estimating $E[Y|X]$, we are also estimating $Var(Y|X)$.\nThis is a potential drawback to the Poisson model, because there is no variance parameter to estimate, and so incorrect models can give wildly inaccurate standard errors (frequently unrealistically small).\nA better model is a quasi-Poisson model, for which the variance is proportional to the mean, but not necessarily equal to it.\nThe negative binomial regression model is also commonly used to address over-dispersed count data where the variance exceeds the mean.\n\nThe canonical link function for Poisson outcomes is the natural logarithm.\nWhen we use a log-link, we can write\n\n$$E[Y|X] = e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}.$$\n\nWe can interpret $\\beta_0$ as follows: for observations which are 0 on all of the predictors, we estimate that the mean (expected) value of the outcome will be $e^{\\beta_0}$.\n\nWe can interpret $\\beta_1$ as follows: adjusting for the other predictors, a one-unit difference in $X_1$ predicts a $(e^{\\beta_1}-1)\\times100 \\%$ difference in the outcome.\n\nGenerally, when using a log-link, we assume that differences in the predictors are associated with multiplicative differences in the outcome.\n\nSome advantages to using an exponential link are\n\n1.  the model is mathematically more tractable and simpler to fit\n\n2.  the model parameters are easy to interpret\n\n3.  the mean of $Y$ is guaranteed to be positive for all values of $X$, which is required by the Poisson distribution\n\nWe can fit a Poisson log-linear regression by writing\n\nglm(Y $\\sim$ X, family = poisson(link = 'log'))\n\nTo fit a quasi-Poisson model, write\n\nglm(Y $\\sim$ X, family = quasipoisson(link = 'log'))\n\nTo fit a negative binomial regression model, write (after loading the `MASS` library)\n\nglm.nb(Y $\\sim$ X, link='log')\n\nTo fit a Poisson regression with an identity link (where coefficients are interpreted as expected differences in the outcome associated with unit differences in the predictor), write\n\nglm(Y $\\sim$ X, family = poisson(link = 'identity'))\n\nTo fit a Poisson regression with a square root link, which is vaguely like a compromise between an identity link and a log link (and is harder to interpret than either), write\n\nglm(Y $\\sim$ X, family = poisson(link = 'sqrt'))\n\nTo fit a Poisson log-linear model with a random intercept and slope, write\n\nglmer(Y $\\sim$ X + (X\\|grp), family = poisson(link = 'log'))\n\n## Dichotomous regression models\n\nWhen predicting either successes and failures, or proportions, we can use a model with a binomial outcome.\nHere we'll focus on models where the data is represented as individual successes and failures.\nThe canonical model for these data is logistic regression, where\n\n$$logit(E[Y|X]) \\equiv \\log\\left(\\frac{P(Y=1|X)}{1-P(Y=1|X)}\\right) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$ $$Y \\sim Binomial(1, E[Y|X])$$\n\nWe can rewrite this model as\n\n$$odds(Y) = \\frac{P(Y=1|X)}{1-P(Y=1|X)} = e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}$$\n\nor\n\n$$P(Y=1|X) = \\frac{e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}{1 + e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}$$\n\nWe can interpret $\\beta_0$ as follows: for observations which are 0 on all of the predictors, we estimate that the mean value of the outcome will be $\\frac{e^{\\beta_0}}{1 + e^{\\beta_0}}$.\nThat is, we estimate that the probability of the outcome being a 'success' (assuming 'success' is coded as a 1) will be $\\frac{e^{\\beta_0}}{1 + e^{\\beta_0}}$.\n\nWe can interpret $\\beta_1$ as follows: adjusting for the other predictors, a one-unit difference in $X_1$ predicts a $\\beta_1$ difference in the log-odds of the outcome being one, or a $(e^{\\beta_1}-1)\\times100\\%$ difference in the odds of the outcome.\nUnfortunately, the change in probability of a unit change depends on where the starting point is, so there is no easy way to interpret these coefficients in terms of direct probability.\nOne can calculate the estimated change for specific units, however, and look at the distribution of those changes.\n\nOther possible link functions include the probit (which uses a Normal CDF to link $\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$ to $P(Y=1|X)$), or the complementary log-log (which allows $P(Y = 1|X)$ to be asymmetric in the predictors), among others.\n\n### Example\n\n### How to fit a GLM\n\nWe can fit a logistic regression model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'logit'))\n\nWe can fit a probit regression model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'probit'))\n\nWe can fit a complementary log-log model by writing\n\nglm(Y $\\sim$ X, family = binomial(link = 'cloglog'))\n\nWe can allow a random slope and intercept by writing\n\nglmer(Y $\\sim$ X + (X\\|grp), family = binomial(link = 'logit'))\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"pygments","output-file":"interpreting_glms.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"theme":"cosmo","code-copy":true,"title":"Interpreting GLMs","author":"Luke Miratrix & Joe McIntyre"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"pygments","output-file":"interpreting_glms.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"documentclass":"scrreprt","title":"Interpreting GLMs","author":"Luke Miratrix & Joe McIntyre"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}