{"title":"Code for HSB Example in Chapter 4 of R&B","markdown":{"yaml":{"title":"Code for HSB Example in Chapter 4 of R&B","author":"Luke Miratrix","editor":{"markdown":{"wrap":"sentence"}}},"headingText":"R Setup","containsRefs":false,"markdown":"\n\n```{r, echo = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nknitr::opts_chunk$set(warning = FALSE)\nknitr::opts_chunk$set(message = FALSE)\n```\n\nThis script builds everything from Chapter 4 of Raudenbush and Bryk in R.\nIt is a very useful script for getting pretty much all the code you would need for a conventional multilevel analysis.\nThe code is divided by each table or plot from the chapter.\n\n\n```{r}\nlibrary(foreign) #this lets us read in spss files\nlibrary(tidyverse) #this is a broad package that allows us to do lots of data management-y things (and ggplot!)\nlibrary(lme4) #this allows us to run MLM\nlibrary(arm) #this allows us to display MLM\nlibrary( lmerTest ) # this puts p-values on the summary() command for fixed effects\n```\n\n## Load HS&B data\n\n```{r}\n# Read student data\nstud.dat = read.spss( \"data/hsb1.sav\", to.data.frame=TRUE )\n\n# Read in school data\nsch.dat = read.spss( \"data/hsb2.sav\", to.data.frame=TRUE )\n\n# Make single data frame with all variables, keep all students even if they\n# don't match to a school\ndat = merge( stud.dat, sch.dat, by=\"id\", all.x=TRUE )\n```\n\n## Table 4.1 Descriptive summaries\n\n```{r}\n## Get mean and SD of the Level 1 variables, rounded to 2 decimal places\n# math achievement\nround(mean(dat$mathach),2)\nround(sd(dat$mathach),2)\n\n# ses\nround(mean(dat$ses),2)\nround(sd(dat$ses),2)\n\n## Get mean and SD of Level 2 variables, round to 2 decimal places\n# NOTE: we are getting these from the SCHOOL-LEVEL FILE\n# sector\nround(mean(sch.dat$sector),2) # this answers \"what percent of schools are catholic?\"\nround(sd(sch.dat$sector),2)\n\n# mean ses\nround(mean(sch.dat$meanses),2) # this answers \"what is the average of the school-average SES values?\"\nround(sd(sch.dat$meanses),2)\n\n# NOTE: if we used the student-level or \"dat\" file, we would be answering the\n# following questions:\n# * what percent of students attend a catholic school?\n# * what is the average student ses? <- this would match what we calculated\n# ourselves if we had the entire school in our sample\n```\n\n## Table 4.2: One-Way ANOVA (i.e uncontrolled random intercept)\n\n```{r}\n## Fit the model described \nmod4.2 <- lmer(mathach ~ 1 + (1|id), data=dat)\n# Peek at the results\ndisplay(mod4.2)\n\n## Extract the fixed effect coefficient (and it's standard error)\nfixef(mod4.2) # extracts the fixed effect coefficient(s)\nse.coef(mod4.2)$fixef #extracts the standard errors for the fixed effect(s)\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.2)\n\n# To get the variances, we extract each part and square it\n# variance of random intercept\n(sigma.hat(mod4.2)$sigma$id)^2\n\n# variance of level 1 residual (easier to extract)\nsigma(mod4.2)^2 \n# could also use the more complicated formula that we used with the intercept.\n# If we do, we get the same thing\nsigma.hat(mod4.2)$sigma$data^2\n\n# Inference on the need for a random intercept\n# Thus uses the book's way of calculating a test statistic with a\n# chi-squared distribution.\n\nschools = dat %>% group_by( id ) %>%\n  summarise( nj = n(),\n             Y.bar.j = mean( mathach ) )\ngamma.00 = fixef( mod4.2 )[[1]]\nsigma.2 = sigma(mod4.2)^2 \nH = sum( schools$nj * (schools$Y.bar.j - gamma.00)^2 / sigma.2 )\nH\n# our p-value\npchisq( H, df = nrow( schools ) - 1, lower.tail = FALSE )\n\n\n# calculating the ICC\ntau.00 = VarCorr(mod4.2)$id[1,1]\nrho.hat = tau.00 / (tau.00 + sigma.2 )\nrho.hat\n\n# Calculating reliability for each school mean. (Here it is purely a function of\n# students in the school.  More students, more info, and thus more reliable.)\nsigma.2 = sigma(mod4.2)^2 \ntau.00 = VarCorr(mod4.2)$id[1,1]\nlambda = tau.00 / ( tau.00 + sigma.2 / schools$nj )\nmean( lambda )\n\n# A bonus graph of the reliabilities\nqplot( lambda )\n```\n\n## Table 4.3 Means as Outcomes Model\n\n```{r}\n# (i.e. random intercept with Level 2 predictor)\n## Fit the model described \nmod4.3 <- lmer(mathach ~ 1 + meanses + (1|id), data=dat)\n\n# Peek at the results\ndisplay(mod4.3)\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\nfixef(mod4.3) # extracts the fixed effect coefficients\n# NOTE: you can call them separately by \"indexing\" them\n# just the intercept\nfixef(mod4.3)[1]\n# just coefficient on mean ses\nfixef(mod4.3)[2]\n\n\nse.coef(mod4.3)$fixef #extracts the standard errors for the fixed effect(s)\n\n## Calculate (or extract) the t-ratio (aka the t-statistic)\n\n# NOTE: the author's don't present this for the intercept, because we often\n# don't care. But it is presented here for completeness\n\n# tstats for intercept\nfixef(mod4.3)[1]/se.coef(mod4.3)$fixef[1]\n\n# tstat mean ses\nfixef(mod4.3)[2]/se.coef(mod4.3)$fixef[2]\n\n# tstat extracted - this does both variables at once! \ncoef(summary(mod4.3))[,\"t value\"]\n\n# NOTE: Let's look at what is happening here:\ncoef(summary(mod4.3)) # gives us all the fixed effect statistics we could want\n\n# the [ ] is called \"indexing\" - it's a way of subsetting data by telling R\n# which [rows,columns] you want to see we are telling R that we want ALL rows \"[\n# ,\" but only the column labeled \"t value\"\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.3)\n\n# To get the variances, we extract each part and square it\n# variance of random intercept\n(sigma.hat(mod4.3)$sigma$id)^2\n\n# variance of level 1 residual\nsigma(mod4.3)^2 \n\n# Range of plausible values for school means for schools with mean SES of 0:\n# See page 73-74)\nfixef( mod4.3 )[[1]] + c(-1.96, 1.96) * (sigma.hat(mod4.3)$sigma$id)\n# Compare to our model without mean ses\nfixef( mod4.2 )[[1]] + c(-1.96, 1.96) * (sigma.hat(mod4.2)$sigma$id)\n\n# Proportion reduction in variance or \"variance explained\" at level 2\ntau.00.anova = (sigma.hat(mod4.2)$sigma$id)^2\ntau.00.meanses = (sigma.hat(mod4.3)$sigma$id)^2\n(tau.00.anova-tau.00.meanses) / tau.00.anova\n\n## Inference on the random effects\nschools = merge( schools, sch.dat, by=\"id\" )\ngamma.00 = fixef( mod4.3 )[[1]]\ngamma.01 = fixef( mod4.3 )[[2]]\nschools = mutate( schools, resid = Y.bar.j - gamma.00 - gamma.01*meanses )\nH = sum( schools$nj * schools$resid^2 ) / sigma(mod4.3)^2 \nH\npchisq( H, nrow( schools ) - 2, lower.tail = FALSE )\n\n\n## Reliability revisited (from pg 75)\nmod4.3\nu.hat = coef( mod4.3 )$id\nhead( u.hat )\nsigma.2 = sigma(mod4.3)^2 \ntau.00 = VarCorr(mod4.3)$id[1,1]\nsigma.2\ntau.00\n\n# These are the individual reliabilities---how well we can separate schools with the same Mean SES\n# (So it is _conditional_ on the mean SES of the schools.)\nlambda.j = tau.00 / (tau.00 + (sigma.2 / schools$nj))\nmean( lambda.j )\n```\n\n## Table 4.4 Random coefficient model (i.e. random slope)\n\n```{r}\n# group-mean center ses  \ndat <- dat %>% group_by( id ) %>% \n  mutate( ses_grpcenter = ses - mean(ses) )\n\n## Fit the model described \nmod4.4 <- lmer(mathach ~ 1 + ses_grpcenter + ( 1 + ses_grpcenter | id ), data=dat)\n# Peek at the results\ndisplay(mod4.4)\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\ncoef(summary(mod4.4)) #this reproduces the whole first panel, though methods used above also work\n\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.4) \n\n# variance of random effects\n(sigma.hat(mod4.4)$sigma$id)^2\n# NOTE: to extract one or the other, you can use indexing\n(sigma.hat(mod4.4)$sigma$id[1])^2 #this is just the intercept random effect\n\n# variance of level 1 residual\nsigma(mod4.4)^2\n```\n\n## Table 4.5 Intercepts and Slopes as Outcomes Model\n\n```{r}\n## Fit the model described \nmod4.5 <- lmer(mathach ~ 1 + meanses + sector + ses_grpcenter*(meanses + sector) + ( 1 + ses_grpcenter | id ), data=dat)\n\n# NOTE: The code above allows the coefficients to appear in the same order as in Table 4.5\n\n# R automatically includes the main effects, so this model can be written more\n# concisely as shown below:\n#\n# lmer(mathach ~ 1 + ses_grpcenter*(meanses + sector) + ( 1 + ses_grpcenter | id ), data=dat)\n\n# Peek at the results\ndisplay(mod4.5)\n\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\n#this reproduces the whole first panel, though methods used above also work\ncoef(summary(mod4.5))\n\n# NOTE: there is a slight descrepancy in the estimate for meanses:ses_grpcenter and \n# the t-statistics for meanses:ses_grpcenter and sector:ses_grpcenter; nothing that \n# changes the interpretations, however.\n\n\n# Testing the need for sector  (see page 82)\n# (We use a likelihood ratio test with the anova() function)\nmod4.5.null <- lmer(mathach ~ 1 + meanses + ses_grpcenter*(meanses) + ( 1 + ses_grpcenter | id ), data=dat)\nanova( mod4.5, mod4.5.null )\n\n# Testing the need for random slope  (see page 84)\n# (We use a likelihood ratio test with the anova() function)\nmod4.5.null.slope <- lmer(mathach ~ 1 + meanses + sector + ses_grpcenter*(meanses + sector) + ( 1 | id ), data=dat) \nanova( mod4.5, mod4.5.null.slope )\n```\n\n## Figure 4.1\n\nNOTE: Figure 4.1 is a graphical display using the results from Model/Table 4.5\n\nThe solid line represents the slope of the gamma-01 coefficient; this is the same in public and catholic schools.\nThe dotted lines represent the the slope for individual schools with \"prototypical\" values of meanses (-1,0,1 standard deviations from mean)\n\n```{r}\n\n\n# to calculate this, we should note a few values: \navg_meanses <- mean(dat$meanses) #average of mean ses var\nhigh_meanses <- mean(dat$meanses) + sd(dat$meanses) # 1 sd above avg meanses\nlow_meanses <- mean(dat$meanses) - sd(dat$meanses) # 1 sd below avg meanses\n\nfake.students = expand.grid( id = -1,\n                             meanses = c( low_meanses, avg_meanses, high_meanses ),\n                             sector = c( 0, 1 ),\n                             ses_grpcenter = c( -1, 0, 1 ) )\nfake.students = mutate( fake.students, ses = meanses + ses_grpcenter )\nfake.students$mathach = predict( mod4.5, newdata=fake.students, allow.new.levels = TRUE )\nfake.schools = filter( fake.students, ses_grpcenter == 0 )\n\nggplot( fake.students, aes( ses, mathach ) ) + \n  facet_wrap( ~ sector ) +\n  geom_line( aes( group=meanses ), lty = 2 ) +\n  geom_line( data=fake.schools, aes( x = ses, y = mathach ) ) +\n  geom_point( data=fake.schools, aes( x = ses, y = mathach ) )\n```\n\n## Set-up for remaining tables/figures of chapter\n\nIn order to create table 4.6 and the following 2 graphs, we will need to prepare a new dataset.\nThese next lines of code do that.\n\n```{r}\n## Start with school level data frame and keep variables interesting to our model comparison\nmod.comp <- dplyr::select( sch.dat, id, meanses, sector )\n\n## Add in number of observations per school \nn_j <- dat %>% group_by( id ) %>%\n  dplyr::summarise(n_j = n())\n\nmod.comp <- merge(mod.comp, n_j, by=\"id\")\nhead( mod.comp )\n\n## Run site-specific OLS for each school and save estimates \n\n# Calculate global (not group) centered ses\ndat$ses_centered <- dat$ses - mean(dat$ses)\n\n# This is the \"for loop\" method of generating an estimate for each of many small\n# worlds (schools). See lecture 2.3 code for the \"tidyverse\" way.\nest.ols <- matrix(nrow=160,ncol=2) #create a matrix to store estimates \nse.ols <- matrix(nrow=160,ncol=2) #create matrix to store standard errors\n\nfor (i in 1:length(unique(dat$id))){ #looping across the 160 different values of id\n    id <- unique(dat$id)[i] #pick the value of id we want\n    mod <- lm(mathach ~ 1 + ses_grpcenter, data=dat[dat$id==id,]) #run the model on students in that 1 school\n    est.ols[i,] <- coef( mod ) #save the setimates in the matrix we created\n    se.ols[i,] <- se.coef( mod ) # and the SEs\n}\n\n#convert the matrix to a dataframe and attach the schoolid info\nest.ols <- as.data.frame(est.ols)\nest.ols$id <- sch.dat$id\nnames(est.ols) <- c( 'b0_ols', 'b1_ols', 'id' )\n\n#store standard errors for later\nse.ols <- as.data.frame(se.ols)\nse.ols$id <- sch.dat$id\nnames(se.ols) <- c( 'se_b0_ols', 'se_b1_ols', 'id' )\n\nmod.comp <- merge(mod.comp, est.ols, by='id')\nmod.comp <- merge(mod.comp, se.ols, by='id' )\nhead( mod.comp )\n\n# We are done running OLS on each of our schools and storing the results.\n\n## Extract site-specific coefficients from \"unconditional model\" (model 4.4)\nest4.4 <- coef(mod4.4)$id\nnames(est4.4) <- c('b0_uncond', 'b1_uncond') #rename\nest4.4$id = rownames( est4.4 )\n\n## Extract site-specific coefficients from the \"conditional model\" (model 4.5)\nest4.5 <- coef(mod4.5)$id\nhead( est4.5 )\nest4.5$id = rownames( est4.5 )\n\n# Now we need to calculate the point estimates using our individual regression equations\n# including our level-2 values for each school\n# (This is a bit of a pain.)\nest4.5 = merge( est4.5, mod.comp, by=\"id\", suffixes = c( \"\", \".v\" ) )\nhead( est4.5 )\nest4.5 = mutate( est4.5, \n                 b0_cond = `(Intercept)` + sector * sector.v + meanses * meanses.v,\n                 b1_cond = ses_grpcenter + `sector:ses_grpcenter` * sector.v + `meanses:ses_grpcenter` * meanses.v )\n\nest4.5 = dplyr::select( est4.5, id, b0_cond, b1_cond )\n\n\n## Combine the MLM estimates into 1 dataset with ids\nest.mlm <- merge( est4.4, est4.5, by=\"id\" )\n\n# Merge all the estimates together by school id\nmod.comp <- merge(mod.comp,est.mlm,by = 'id',all=TRUE)\n\nhead( mod.comp )\n```\n\n## Table 4.6 Comparing site-specific estimates from different models\n\n```{r}\n## Create the list of rows that B&R include in the table p. 87\nkeeprows <- c(4, 15, 17, 22, 27, 53, 69, 75, 81, 90, 135, 153)\n\n## Limit data to the rows of interest, and print the columns in Table 4.6 in the correct order\ntab4.6 <- mod.comp[keeprows, c('b0_ols','b1_ols','b0_uncond','b1_uncond','b0_cond','b1_cond','n_j','meanses','sector') ]\n\n\n## Print Table 4.6 -- the Empirical Bayes from conditional model (b0_cond, b1_cond) are waaaaaay off\nround(tab4.6,2)\n```\n\n## Figure 4.2 : Scatter plots of the estimates from 2 unconstrained models\n\n```{r}\n## Panel (a) and Panel (b) are plotted on the same graph \nggplot(data=mod.comp,aes()) + \n  geom_point(aes(x=b1_ols,y=b0_ols),color='black',alpha=0.7) + \n  geom_point(aes(x=b1_uncond,y=b0_uncond),color='blue',alpha=0.7) + \n  labs(title=\"Black=OLS; Blue=Unconditional EB\") +\n  xlim(-5,8) + ylim(2,20)\n```\n\n## Figure 4.3 : Scatter plots of residuals from the OLS & Constrained MLM model\n\n```{r}\n## Luke: Equation 4.271 and 4.27b (p. 92) are allegedly how we calculate the intercept and slope residuals \n## But I'm not sure where the estimates for the gamma-hat terms come from; the OLS model only includes\n## individual-level ses\n\n# trying it here with the predictions from conditional EB\nfes = fixef( mod4.5 )\nfes\n\nmod.comp = mutate( mod.comp,\n                   u0_ols = b0_ols - (fes[1] + fes[2]*meanses + fes[3]*sector),\n                   u1_ols = b1_ols - (fes[4] + fes[5]*meanses + fes[6]*sector)  )\n\n\n## Panel (a) and (b) plotted on same graph\n\nmod.comp = mutate( mod.comp, \n                   u0_cond = b0_cond - (fes[1] + fes[2]*meanses + fes[3]*sector),\n                   u1_cond = b1_cond - (fes[4] + fes[5]*meanses + fes[6]*sector)  )\n\nhead( mod.comp )\nnrow( mod.comp )\nggplot(data=mod.comp, aes( pch=as.factor(sector)) ) + \n         geom_point(aes(x=u1_ols, y=u0_ols),color='black', alpha=0.7) +   \n         geom_point(aes(x=u1_cond, y=u0_cond),color='blue', alpha=0.7) + \n         labs(title = \"Black: OLS, Blue: Conditional EB\") + \n         xlim(-6,6) + ylim(-8,8)\n\n\n# To get in two-panel format we need to get our data to long format\nmod.comp.ols = data.frame( sector = mod.comp$sector,\n                           u0 = mod.comp$u0_ols,\n                           u1 = mod.comp$u1_ols )\nmod.comp.EB = data.frame(  sector = mod.comp$sector,\n                           u0 = mod.comp$u0_cond,\n                           u1 = mod.comp$u1_cond )\nmod.comp.l = bind_rows( ols=mod.comp.ols, cond = mod.comp.EB, .id = \"method\" )\n\nggplot(data=mod.comp.l, aes( u1, u0, pch=as.factor(sector)) ) + \n  facet_wrap( ~ method ) +\n  geom_point()\n```\n\n## Table 4.7 : pg 94\n\n```{r}\n\n\n# This section is not very good--I would skip.\n# Generating confidence intervals for individual random intercepts and slopes is a weird business.\n\n# OLS First:\n\n# Doing it by fitting OLS on our subset\nsch.2305 = filter( dat, id == 2305 )\nhead( sch.2305 )\nM.2305 = lm( mathach ~ ses_grpcenter, data=sch.2305 )\nM.2305\nconfint( M.2305 )\n\nsch.8367 = filter( dat, id == 8367 )\nhead( sch.8367 )\nM.8367 = lm( mathach ~ ses_grpcenter, data=sch.8367 )\nM.8367\nconfint( M.8367 )\n\n\n# Use SE from earlier to get confint\nest4.7 <- mod.comp[c(22,135),]\nest4.7\n\n# CI for intercept and slope using our normal and stored SEs.\n# (Not taking t distribution into account changes things, as does not\n# taking the uncertainty in the fixed effects for the EB CIs.  So this is\n# very approximate.)\nse_uncond = as.data.frame( se.coef(mod4.4)$id )\nhead( se_uncond )\nnames( se_uncond ) = c(\"se_b0_uncond\",\"se_b1_uncond\" )\nse_cond = as.data.frame( se.coef(  mod4.5 )$id )\nnames( se_cond ) = c(\"se_b0_cond\",\"se_b1_cond\" )\nhead( se_cond )\nse_uncond$id = rownames( se_uncond )\nse_cond$id = rownames( se_cond )\nest4.7 = merge( est4.7, se_uncond, by=\"id\" )\nest4.7 = merge( est4.7, se_cond, by=\"id\" )\n\nest4.7.int = mutate( est4.7, \n                 CI.low.ols = b0_ols + - 1.96 * se_b0_ols,\n                 CI.high.ols = b0_ols + 1.96 * se_b0_ols,\n                 CI.low.uncond = b0_uncond + - 1.96 * se_b0_uncond,\n                 CI.high.uncond = b0_uncond + 1.96 * se_b0_uncond,\n                 CI.low.cond = b0_cond + - 1.96 * se_b0_cond,\n                 CI.high.cond = b0_cond + 1.96 * se_b0_cond )\n\ndplyr::select( est4.7.int, starts_with(\"CI\" ) )\n\n\nest4.7.slope = mutate( est4.7, \n                     CI.low.ols = b1_ols + - 1.96 * se_b1_ols,\n                     CI.high.ols = b1_ols + 1.96 * se_b1_ols,\n                     CI.low.uncond = b1_uncond + - 1.96 * se_b1_uncond,\n                     CI.high.uncond = b1_uncond + 1.96 * se_b1_uncond,\n                     CI.low.cond = b1_cond + - 1.96 * se_b1_cond,\n                     CI.high.cond = b1_cond + 1.96 * se_b1_cond )\n\ndplyr::select( est4.7.slope, starts_with(\"CI\" ) )\n```\n","srcMarkdownNoYaml":"\n\n```{r, echo = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nknitr::opts_chunk$set(warning = FALSE)\nknitr::opts_chunk$set(message = FALSE)\n```\n\nThis script builds everything from Chapter 4 of Raudenbush and Bryk in R.\nIt is a very useful script for getting pretty much all the code you would need for a conventional multilevel analysis.\nThe code is divided by each table or plot from the chapter.\n\n## R Setup\n\n```{r}\nlibrary(foreign) #this lets us read in spss files\nlibrary(tidyverse) #this is a broad package that allows us to do lots of data management-y things (and ggplot!)\nlibrary(lme4) #this allows us to run MLM\nlibrary(arm) #this allows us to display MLM\nlibrary( lmerTest ) # this puts p-values on the summary() command for fixed effects\n```\n\n## Load HS&B data\n\n```{r}\n# Read student data\nstud.dat = read.spss( \"data/hsb1.sav\", to.data.frame=TRUE )\n\n# Read in school data\nsch.dat = read.spss( \"data/hsb2.sav\", to.data.frame=TRUE )\n\n# Make single data frame with all variables, keep all students even if they\n# don't match to a school\ndat = merge( stud.dat, sch.dat, by=\"id\", all.x=TRUE )\n```\n\n## Table 4.1 Descriptive summaries\n\n```{r}\n## Get mean and SD of the Level 1 variables, rounded to 2 decimal places\n# math achievement\nround(mean(dat$mathach),2)\nround(sd(dat$mathach),2)\n\n# ses\nround(mean(dat$ses),2)\nround(sd(dat$ses),2)\n\n## Get mean and SD of Level 2 variables, round to 2 decimal places\n# NOTE: we are getting these from the SCHOOL-LEVEL FILE\n# sector\nround(mean(sch.dat$sector),2) # this answers \"what percent of schools are catholic?\"\nround(sd(sch.dat$sector),2)\n\n# mean ses\nround(mean(sch.dat$meanses),2) # this answers \"what is the average of the school-average SES values?\"\nround(sd(sch.dat$meanses),2)\n\n# NOTE: if we used the student-level or \"dat\" file, we would be answering the\n# following questions:\n# * what percent of students attend a catholic school?\n# * what is the average student ses? <- this would match what we calculated\n# ourselves if we had the entire school in our sample\n```\n\n## Table 4.2: One-Way ANOVA (i.e uncontrolled random intercept)\n\n```{r}\n## Fit the model described \nmod4.2 <- lmer(mathach ~ 1 + (1|id), data=dat)\n# Peek at the results\ndisplay(mod4.2)\n\n## Extract the fixed effect coefficient (and it's standard error)\nfixef(mod4.2) # extracts the fixed effect coefficient(s)\nse.coef(mod4.2)$fixef #extracts the standard errors for the fixed effect(s)\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.2)\n\n# To get the variances, we extract each part and square it\n# variance of random intercept\n(sigma.hat(mod4.2)$sigma$id)^2\n\n# variance of level 1 residual (easier to extract)\nsigma(mod4.2)^2 \n# could also use the more complicated formula that we used with the intercept.\n# If we do, we get the same thing\nsigma.hat(mod4.2)$sigma$data^2\n\n# Inference on the need for a random intercept\n# Thus uses the book's way of calculating a test statistic with a\n# chi-squared distribution.\n\nschools = dat %>% group_by( id ) %>%\n  summarise( nj = n(),\n             Y.bar.j = mean( mathach ) )\ngamma.00 = fixef( mod4.2 )[[1]]\nsigma.2 = sigma(mod4.2)^2 \nH = sum( schools$nj * (schools$Y.bar.j - gamma.00)^2 / sigma.2 )\nH\n# our p-value\npchisq( H, df = nrow( schools ) - 1, lower.tail = FALSE )\n\n\n# calculating the ICC\ntau.00 = VarCorr(mod4.2)$id[1,1]\nrho.hat = tau.00 / (tau.00 + sigma.2 )\nrho.hat\n\n# Calculating reliability for each school mean. (Here it is purely a function of\n# students in the school.  More students, more info, and thus more reliable.)\nsigma.2 = sigma(mod4.2)^2 \ntau.00 = VarCorr(mod4.2)$id[1,1]\nlambda = tau.00 / ( tau.00 + sigma.2 / schools$nj )\nmean( lambda )\n\n# A bonus graph of the reliabilities\nqplot( lambda )\n```\n\n## Table 4.3 Means as Outcomes Model\n\n```{r}\n# (i.e. random intercept with Level 2 predictor)\n## Fit the model described \nmod4.3 <- lmer(mathach ~ 1 + meanses + (1|id), data=dat)\n\n# Peek at the results\ndisplay(mod4.3)\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\nfixef(mod4.3) # extracts the fixed effect coefficients\n# NOTE: you can call them separately by \"indexing\" them\n# just the intercept\nfixef(mod4.3)[1]\n# just coefficient on mean ses\nfixef(mod4.3)[2]\n\n\nse.coef(mod4.3)$fixef #extracts the standard errors for the fixed effect(s)\n\n## Calculate (or extract) the t-ratio (aka the t-statistic)\n\n# NOTE: the author's don't present this for the intercept, because we often\n# don't care. But it is presented here for completeness\n\n# tstats for intercept\nfixef(mod4.3)[1]/se.coef(mod4.3)$fixef[1]\n\n# tstat mean ses\nfixef(mod4.3)[2]/se.coef(mod4.3)$fixef[2]\n\n# tstat extracted - this does both variables at once! \ncoef(summary(mod4.3))[,\"t value\"]\n\n# NOTE: Let's look at what is happening here:\ncoef(summary(mod4.3)) # gives us all the fixed effect statistics we could want\n\n# the [ ] is called \"indexing\" - it's a way of subsetting data by telling R\n# which [rows,columns] you want to see we are telling R that we want ALL rows \"[\n# ,\" but only the column labeled \"t value\"\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.3)\n\n# To get the variances, we extract each part and square it\n# variance of random intercept\n(sigma.hat(mod4.3)$sigma$id)^2\n\n# variance of level 1 residual\nsigma(mod4.3)^2 \n\n# Range of plausible values for school means for schools with mean SES of 0:\n# See page 73-74)\nfixef( mod4.3 )[[1]] + c(-1.96, 1.96) * (sigma.hat(mod4.3)$sigma$id)\n# Compare to our model without mean ses\nfixef( mod4.2 )[[1]] + c(-1.96, 1.96) * (sigma.hat(mod4.2)$sigma$id)\n\n# Proportion reduction in variance or \"variance explained\" at level 2\ntau.00.anova = (sigma.hat(mod4.2)$sigma$id)^2\ntau.00.meanses = (sigma.hat(mod4.3)$sigma$id)^2\n(tau.00.anova-tau.00.meanses) / tau.00.anova\n\n## Inference on the random effects\nschools = merge( schools, sch.dat, by=\"id\" )\ngamma.00 = fixef( mod4.3 )[[1]]\ngamma.01 = fixef( mod4.3 )[[2]]\nschools = mutate( schools, resid = Y.bar.j - gamma.00 - gamma.01*meanses )\nH = sum( schools$nj * schools$resid^2 ) / sigma(mod4.3)^2 \nH\npchisq( H, nrow( schools ) - 2, lower.tail = FALSE )\n\n\n## Reliability revisited (from pg 75)\nmod4.3\nu.hat = coef( mod4.3 )$id\nhead( u.hat )\nsigma.2 = sigma(mod4.3)^2 \ntau.00 = VarCorr(mod4.3)$id[1,1]\nsigma.2\ntau.00\n\n# These are the individual reliabilities---how well we can separate schools with the same Mean SES\n# (So it is _conditional_ on the mean SES of the schools.)\nlambda.j = tau.00 / (tau.00 + (sigma.2 / schools$nj))\nmean( lambda.j )\n```\n\n## Table 4.4 Random coefficient model (i.e. random slope)\n\n```{r}\n# group-mean center ses  \ndat <- dat %>% group_by( id ) %>% \n  mutate( ses_grpcenter = ses - mean(ses) )\n\n## Fit the model described \nmod4.4 <- lmer(mathach ~ 1 + ses_grpcenter + ( 1 + ses_grpcenter | id ), data=dat)\n# Peek at the results\ndisplay(mod4.4)\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\ncoef(summary(mod4.4)) #this reproduces the whole first panel, though methods used above also work\n\n\n## Extract the variance components\n# Note: in the model display, we see the SDs, not the variance\nVarCorr(mod4.4) \n\n# variance of random effects\n(sigma.hat(mod4.4)$sigma$id)^2\n# NOTE: to extract one or the other, you can use indexing\n(sigma.hat(mod4.4)$sigma$id[1])^2 #this is just the intercept random effect\n\n# variance of level 1 residual\nsigma(mod4.4)^2\n```\n\n## Table 4.5 Intercepts and Slopes as Outcomes Model\n\n```{r}\n## Fit the model described \nmod4.5 <- lmer(mathach ~ 1 + meanses + sector + ses_grpcenter*(meanses + sector) + ( 1 + ses_grpcenter | id ), data=dat)\n\n# NOTE: The code above allows the coefficients to appear in the same order as in Table 4.5\n\n# R automatically includes the main effects, so this model can be written more\n# concisely as shown below:\n#\n# lmer(mathach ~ 1 + ses_grpcenter*(meanses + sector) + ( 1 + ses_grpcenter | id ), data=dat)\n\n# Peek at the results\ndisplay(mod4.5)\n\n\n## Extract the fixed effect coefficients (and standard errors/t-statistics)\n#this reproduces the whole first panel, though methods used above also work\ncoef(summary(mod4.5))\n\n# NOTE: there is a slight descrepancy in the estimate for meanses:ses_grpcenter and \n# the t-statistics for meanses:ses_grpcenter and sector:ses_grpcenter; nothing that \n# changes the interpretations, however.\n\n\n# Testing the need for sector  (see page 82)\n# (We use a likelihood ratio test with the anova() function)\nmod4.5.null <- lmer(mathach ~ 1 + meanses + ses_grpcenter*(meanses) + ( 1 + ses_grpcenter | id ), data=dat)\nanova( mod4.5, mod4.5.null )\n\n# Testing the need for random slope  (see page 84)\n# (We use a likelihood ratio test with the anova() function)\nmod4.5.null.slope <- lmer(mathach ~ 1 + meanses + sector + ses_grpcenter*(meanses + sector) + ( 1 | id ), data=dat) \nanova( mod4.5, mod4.5.null.slope )\n```\n\n## Figure 4.1\n\nNOTE: Figure 4.1 is a graphical display using the results from Model/Table 4.5\n\nThe solid line represents the slope of the gamma-01 coefficient; this is the same in public and catholic schools.\nThe dotted lines represent the the slope for individual schools with \"prototypical\" values of meanses (-1,0,1 standard deviations from mean)\n\n```{r}\n\n\n# to calculate this, we should note a few values: \navg_meanses <- mean(dat$meanses) #average of mean ses var\nhigh_meanses <- mean(dat$meanses) + sd(dat$meanses) # 1 sd above avg meanses\nlow_meanses <- mean(dat$meanses) - sd(dat$meanses) # 1 sd below avg meanses\n\nfake.students = expand.grid( id = -1,\n                             meanses = c( low_meanses, avg_meanses, high_meanses ),\n                             sector = c( 0, 1 ),\n                             ses_grpcenter = c( -1, 0, 1 ) )\nfake.students = mutate( fake.students, ses = meanses + ses_grpcenter )\nfake.students$mathach = predict( mod4.5, newdata=fake.students, allow.new.levels = TRUE )\nfake.schools = filter( fake.students, ses_grpcenter == 0 )\n\nggplot( fake.students, aes( ses, mathach ) ) + \n  facet_wrap( ~ sector ) +\n  geom_line( aes( group=meanses ), lty = 2 ) +\n  geom_line( data=fake.schools, aes( x = ses, y = mathach ) ) +\n  geom_point( data=fake.schools, aes( x = ses, y = mathach ) )\n```\n\n## Set-up for remaining tables/figures of chapter\n\nIn order to create table 4.6 and the following 2 graphs, we will need to prepare a new dataset.\nThese next lines of code do that.\n\n```{r}\n## Start with school level data frame and keep variables interesting to our model comparison\nmod.comp <- dplyr::select( sch.dat, id, meanses, sector )\n\n## Add in number of observations per school \nn_j <- dat %>% group_by( id ) %>%\n  dplyr::summarise(n_j = n())\n\nmod.comp <- merge(mod.comp, n_j, by=\"id\")\nhead( mod.comp )\n\n## Run site-specific OLS for each school and save estimates \n\n# Calculate global (not group) centered ses\ndat$ses_centered <- dat$ses - mean(dat$ses)\n\n# This is the \"for loop\" method of generating an estimate for each of many small\n# worlds (schools). See lecture 2.3 code for the \"tidyverse\" way.\nest.ols <- matrix(nrow=160,ncol=2) #create a matrix to store estimates \nse.ols <- matrix(nrow=160,ncol=2) #create matrix to store standard errors\n\nfor (i in 1:length(unique(dat$id))){ #looping across the 160 different values of id\n    id <- unique(dat$id)[i] #pick the value of id we want\n    mod <- lm(mathach ~ 1 + ses_grpcenter, data=dat[dat$id==id,]) #run the model on students in that 1 school\n    est.ols[i,] <- coef( mod ) #save the setimates in the matrix we created\n    se.ols[i,] <- se.coef( mod ) # and the SEs\n}\n\n#convert the matrix to a dataframe and attach the schoolid info\nest.ols <- as.data.frame(est.ols)\nest.ols$id <- sch.dat$id\nnames(est.ols) <- c( 'b0_ols', 'b1_ols', 'id' )\n\n#store standard errors for later\nse.ols <- as.data.frame(se.ols)\nse.ols$id <- sch.dat$id\nnames(se.ols) <- c( 'se_b0_ols', 'se_b1_ols', 'id' )\n\nmod.comp <- merge(mod.comp, est.ols, by='id')\nmod.comp <- merge(mod.comp, se.ols, by='id' )\nhead( mod.comp )\n\n# We are done running OLS on each of our schools and storing the results.\n\n## Extract site-specific coefficients from \"unconditional model\" (model 4.4)\nest4.4 <- coef(mod4.4)$id\nnames(est4.4) <- c('b0_uncond', 'b1_uncond') #rename\nest4.4$id = rownames( est4.4 )\n\n## Extract site-specific coefficients from the \"conditional model\" (model 4.5)\nest4.5 <- coef(mod4.5)$id\nhead( est4.5 )\nest4.5$id = rownames( est4.5 )\n\n# Now we need to calculate the point estimates using our individual regression equations\n# including our level-2 values for each school\n# (This is a bit of a pain.)\nest4.5 = merge( est4.5, mod.comp, by=\"id\", suffixes = c( \"\", \".v\" ) )\nhead( est4.5 )\nest4.5 = mutate( est4.5, \n                 b0_cond = `(Intercept)` + sector * sector.v + meanses * meanses.v,\n                 b1_cond = ses_grpcenter + `sector:ses_grpcenter` * sector.v + `meanses:ses_grpcenter` * meanses.v )\n\nest4.5 = dplyr::select( est4.5, id, b0_cond, b1_cond )\n\n\n## Combine the MLM estimates into 1 dataset with ids\nest.mlm <- merge( est4.4, est4.5, by=\"id\" )\n\n# Merge all the estimates together by school id\nmod.comp <- merge(mod.comp,est.mlm,by = 'id',all=TRUE)\n\nhead( mod.comp )\n```\n\n## Table 4.6 Comparing site-specific estimates from different models\n\n```{r}\n## Create the list of rows that B&R include in the table p. 87\nkeeprows <- c(4, 15, 17, 22, 27, 53, 69, 75, 81, 90, 135, 153)\n\n## Limit data to the rows of interest, and print the columns in Table 4.6 in the correct order\ntab4.6 <- mod.comp[keeprows, c('b0_ols','b1_ols','b0_uncond','b1_uncond','b0_cond','b1_cond','n_j','meanses','sector') ]\n\n\n## Print Table 4.6 -- the Empirical Bayes from conditional model (b0_cond, b1_cond) are waaaaaay off\nround(tab4.6,2)\n```\n\n## Figure 4.2 : Scatter plots of the estimates from 2 unconstrained models\n\n```{r}\n## Panel (a) and Panel (b) are plotted on the same graph \nggplot(data=mod.comp,aes()) + \n  geom_point(aes(x=b1_ols,y=b0_ols),color='black',alpha=0.7) + \n  geom_point(aes(x=b1_uncond,y=b0_uncond),color='blue',alpha=0.7) + \n  labs(title=\"Black=OLS; Blue=Unconditional EB\") +\n  xlim(-5,8) + ylim(2,20)\n```\n\n## Figure 4.3 : Scatter plots of residuals from the OLS & Constrained MLM model\n\n```{r}\n## Luke: Equation 4.271 and 4.27b (p. 92) are allegedly how we calculate the intercept and slope residuals \n## But I'm not sure where the estimates for the gamma-hat terms come from; the OLS model only includes\n## individual-level ses\n\n# trying it here with the predictions from conditional EB\nfes = fixef( mod4.5 )\nfes\n\nmod.comp = mutate( mod.comp,\n                   u0_ols = b0_ols - (fes[1] + fes[2]*meanses + fes[3]*sector),\n                   u1_ols = b1_ols - (fes[4] + fes[5]*meanses + fes[6]*sector)  )\n\n\n## Panel (a) and (b) plotted on same graph\n\nmod.comp = mutate( mod.comp, \n                   u0_cond = b0_cond - (fes[1] + fes[2]*meanses + fes[3]*sector),\n                   u1_cond = b1_cond - (fes[4] + fes[5]*meanses + fes[6]*sector)  )\n\nhead( mod.comp )\nnrow( mod.comp )\nggplot(data=mod.comp, aes( pch=as.factor(sector)) ) + \n         geom_point(aes(x=u1_ols, y=u0_ols),color='black', alpha=0.7) +   \n         geom_point(aes(x=u1_cond, y=u0_cond),color='blue', alpha=0.7) + \n         labs(title = \"Black: OLS, Blue: Conditional EB\") + \n         xlim(-6,6) + ylim(-8,8)\n\n\n# To get in two-panel format we need to get our data to long format\nmod.comp.ols = data.frame( sector = mod.comp$sector,\n                           u0 = mod.comp$u0_ols,\n                           u1 = mod.comp$u1_ols )\nmod.comp.EB = data.frame(  sector = mod.comp$sector,\n                           u0 = mod.comp$u0_cond,\n                           u1 = mod.comp$u1_cond )\nmod.comp.l = bind_rows( ols=mod.comp.ols, cond = mod.comp.EB, .id = \"method\" )\n\nggplot(data=mod.comp.l, aes( u1, u0, pch=as.factor(sector)) ) + \n  facet_wrap( ~ method ) +\n  geom_point()\n```\n\n## Table 4.7 : pg 94\n\n```{r}\n\n\n# This section is not very good--I would skip.\n# Generating confidence intervals for individual random intercepts and slopes is a weird business.\n\n# OLS First:\n\n# Doing it by fitting OLS on our subset\nsch.2305 = filter( dat, id == 2305 )\nhead( sch.2305 )\nM.2305 = lm( mathach ~ ses_grpcenter, data=sch.2305 )\nM.2305\nconfint( M.2305 )\n\nsch.8367 = filter( dat, id == 8367 )\nhead( sch.8367 )\nM.8367 = lm( mathach ~ ses_grpcenter, data=sch.8367 )\nM.8367\nconfint( M.8367 )\n\n\n# Use SE from earlier to get confint\nest4.7 <- mod.comp[c(22,135),]\nest4.7\n\n# CI for intercept and slope using our normal and stored SEs.\n# (Not taking t distribution into account changes things, as does not\n# taking the uncertainty in the fixed effects for the EB CIs.  So this is\n# very approximate.)\nse_uncond = as.data.frame( se.coef(mod4.4)$id )\nhead( se_uncond )\nnames( se_uncond ) = c(\"se_b0_uncond\",\"se_b1_uncond\" )\nse_cond = as.data.frame( se.coef(  mod4.5 )$id )\nnames( se_cond ) = c(\"se_b0_cond\",\"se_b1_cond\" )\nhead( se_cond )\nse_uncond$id = rownames( se_uncond )\nse_cond$id = rownames( se_cond )\nest4.7 = merge( est4.7, se_uncond, by=\"id\" )\nest4.7 = merge( est4.7, se_cond, by=\"id\" )\n\nest4.7.int = mutate( est4.7, \n                 CI.low.ols = b0_ols + - 1.96 * se_b0_ols,\n                 CI.high.ols = b0_ols + 1.96 * se_b0_ols,\n                 CI.low.uncond = b0_uncond + - 1.96 * se_b0_uncond,\n                 CI.high.uncond = b0_uncond + 1.96 * se_b0_uncond,\n                 CI.low.cond = b0_cond + - 1.96 * se_b0_cond,\n                 CI.high.cond = b0_cond + 1.96 * se_b0_cond )\n\ndplyr::select( est4.7.int, starts_with(\"CI\" ) )\n\n\nest4.7.slope = mutate( est4.7, \n                     CI.low.ols = b1_ols + - 1.96 * se_b1_ols,\n                     CI.high.ols = b1_ols + 1.96 * se_b1_ols,\n                     CI.low.uncond = b1_uncond + - 1.96 * se_b1_uncond,\n                     CI.high.uncond = b1_uncond + 1.96 * se_b1_uncond,\n                     CI.low.cond = b1_cond + - 1.96 * se_b1_cond,\n                     CI.high.cond = b1_cond + 1.96 * se_b1_cond )\n\ndplyr::select( est4.7.slope, starts_with(\"CI\" ) )\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"pygments","output-file":"hsb_ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"theme":"cosmo","code-copy":true,"title":"Code for HSB Example in Chapter 4 of R&B","author":"Luke Miratrix"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"pygments","output-file":"hsb_ex.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"output_dir":"docs","editor":{"markdown":{"wrap":"sentence"}},"documentclass":"scrreprt","title":"Code for HSB Example in Chapter 4 of R&B","author":"Luke Miratrix"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}