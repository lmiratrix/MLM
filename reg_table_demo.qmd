# Making Regression and ANOVA Tables {#sec-make-regression-tables}

```{r setup, include=FALSE, message=FALSE, warning=FALSE }

library(tidyverse)
library(lme4)
library(arm)
library(knitr)
library(texreg)
library(stargazer)
library(lmtest)

opts_chunk$set(message=FALSE, warning=FALSE, tidy=FALSE, out.width="4.5in")


## read in data
dat1 <- read.csv("data/MCC_students.csv")
#dat2 <- read.csv("MCC_schools.csv")

## keep relevant variables
vars1 <- c("ID", "esafe", "grade", "gender", "disc", "race_white")
#vars2 <- c("ID", "mean.belong")

dat1 <- dplyr::select(dat1, vars1)
#dat2 <- dplyr::select(dat2, vars2)

## convert grade to numeric
dat1$grade <- gsub("th", "", dat1$grade) ## remove ’th’ with ’’ 
dat1$grade <- as.numeric(dat1$grade) ## convert from char to num

## keep only observations who answered either male or female
dat1 <- filter(dat1, gender %in% c("Female", "Male"))

## make race a factor variable
dat1$race_white <- as.factor(dat1$race_white)

## keep only complete cases
dat1x <- dat1[complete.cases(dat1), ]
#dat2x <- dat2[complete.cases(dat2), ]

#rename dataset
dat <- dat1x
#dat <- merge(dat1x,dat2x,by= "ID")

sch1 = filter( dat1x, ID == 1 )
nrow( sch1 )

dat = dat %>% group_by(ID) %>% 
  mutate(max.grade = max(grade), HS = max.grade >= 9)
dat.g8 <- filter(dat, grade==8)

```

This document demonstrates different ways of making regression tables in your reports, and talks about some weird wrinkles with using them with multilevel modeling.

## The basics of regression tables

For the basics we quickly illustrate regression tables using a subset of the Making Caring Common dataset, which we will eventually discuss in class. This dataset has a measure of emotional safety (our outcome) and we want to see, in a specific school, if this is predicted by gender and/or grade.

Our data look like this:

```{r}
sample_n( sch1, 6 )
```

We fit some models:

```{r}
M_A = lm( esafe ~ grade, data = sch1 )
M_B = lm( esafe ~ grade + gender, data = sch1 )
M_C = lm( esafe ~ grade * gender, data = sch1 )
```

Ok, we have fit our regression models. We can look at big complex printout of a single model like so:

```{r}
summary( M_C )
```

Or we can make *regression tables*. Consider these two packages, the first being `texreg`

```{r}
library( texreg )
screenreg(list(M_A, M_B, M_C))
```

Another is `stargazer`.

```{r}
library( stargazer )
stargazer( M_A, M_B, M_C, header=FALSE, type='text')
```

## Extending to the multilevel model

For our multilevel examples, we use the Making Caring Common data from Project A, and fit data to the 8th grade students only, but do it for all schools. We have made a High School dummy variable.

Our two models we use for demo purposes have a HS term and no HS term:

```{r}
modA <- lmer( esafe ~ 1 + (1 | ID), data=dat.g8)
modB <- lmer( esafe ~ 1 + HS + (1 | ID), data=dat.g8)
```

In the next sections we first show how to get better summary output (according to some folks) and then we walk through making regression tables in a bit more detail than above.

## Getting p-values for lmer output

The `lmerTest` package is a way of making R give you more complete output. We are going to load it, and then put the new lmer models into new variables so we can see how the different model fitting packages work with the regression table packages below.

```{r}
library( lmerTest )
modB.T <- lmer( esafe ~ 1 + HS + (1 | ID), data=dat.g8)
modA.T <- lmer( esafe ~ 1 + (1 | ID), data=dat.g8)

summary( modB.T )
```

## The texreg package

In `texreg` there are two primary functions for table making, one is `screenreg()` and the other is `texreg()`.

### Using screenreg()

Screenreg is fine for MLMs. It looks a bit like raw output, but it is clear and clean. It will take models fit using lmer or lmerTest, no problem.

```{r}
screenreg(list(modA,modB))
```

*Comment:* Note that the number of stars are different for the display vs the summary output! (Look at the HS coefficient for example.) Not good, it would seem.

This is because the $p$-values are calculated using the normal approximation by the screenreg command, and using the $t$-test with approximate degrees of freedom by `lmerTest`. This makes a difference. Consider the following, using the $t$ statistics for the HS variable:

```{r}
2 * pt( -2.733, df=25.77814 )
2 * pnorm( -2.733 )
```

One is below 0.01, and one is not. An extra star!

### Using texreg() and TeX

The `texreg` command is part of the `texreg` package and can be integrated with latex (which you would need to install). Once you do this, when you compile to a pdf, all is well. In the R code chunk you need to include `results="asis"` to get the latex to compile right. E.g., "`r, results="asis"`" when you declare a code chunk.

```{r, results="asis"}
texreg(list(modA,modB), table=FALSE)
```

Note that the `table=FALSE` puts the table right where you want it, not at some random spot latex things is nice. Latex likes to have "floating tables," where it puts the table where there is space; this makes it easier to make the entire formatted page look nice.

## The stargazer package

```{r, results="asis"}
library( stargazer )
stargazer(modA, modB, header=FALSE, type='latex')
```

One issue is stargazer does not include the random effect variances, so the output is quite limited for multilevel modeling. It also has less stringent conditions for when to put down stars. One star is below 0.10, two is below 0.05, and three is below 0.01. This is quite generous. Also it is using the normal approximation.

### Stargazer with lmerTest

Stargazer with lmerTest is a bit fussy. This shows how to make it work if you have loaded the lmerTest package. Recall the lmerTest package makes your lmer commands have p-values and whatnot. But this means your new `lmer()` command is not quite the same as the old---and stargazer is expecting the old. You gix this by lying to R, telling it the new thing is the old thing. This basically works.

Now for stargazer, we need to tell it that our models are the right type. First note:

```{r}
class( modB )
class( modB.T)
```

So we fix as follows:

```{r, results="asis"}
library( stargazer )
class( modB.T ) = "lmerMod" 
class( modA.T ) = "lmerMod" 
stargazer(modA.T, modB.T, header=FALSE, type='latex' )
```

### The sjPlot package

One function, `tab_model` from `sjPlot`, makes nice regression tables:

```{r}
# tabulate the results of our two tip models
library( sjPlot )
tab_model(modA.T, modB.T)
```

## Pretty ANOVA (liklihood ratio test) Tables


```{r, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(tidyverse)
library(knitr)
library(broom)
```

We now turn to how to give a nice display of likelihood ratio test results using the `kable` function.
To show how to make such tables, we first create a fake illustrative data set called `a` that has 100 observations and specifies our outcome `Y` as a funciton of two uncorrelated variables `A` and `B`

```{r}
a <- tibble( A = rnorm( 100 ),
            B = rnorm( 100 ),
            Y = A * 0.2 + B * 0.5 + rnorm( 100, 0, 1 ) )
```

### Run the Models

We fit two models, one with `A` and `B`, the other with just `A`.

```{r}
M1 <- lm( Y~ A + B, data = a )
M2 <- lm( Y ~ A, data = a )
```

### Comparing the Models

We use the `anova` function to compare the two models (see also the chapter on Likelihood Ratio tests).
We see that `B` improves the model fit significantly.

```{r}
aa = anova( M2, M1 )
aa

aa |> 
  tidy() |> 
  kable()
```

### Compare to the Significance test on `B`

Note that the p value for `B` is identical to the ANOVA results above.
Why bother with ANOVA?
It can test more complex hypotheses as well (multiple coefficients, random effects, etc.)

```{r}
M1 |> 
  tidy() |> 
  kable()
```

### Acknowledgements

The ANOVA portion of this chapter was initially drafted by Josh Gilbert

