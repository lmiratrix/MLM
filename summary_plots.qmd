---
title: "Simple tables, plots, and model diagnostics"
author: "Luke Miratrix"
editor: 
  markdown: 
    wrap: sentence
editor_options: 
  chunk_output_type: console
---

```{r loadlibs, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(nlme)
library(haven)
library(lme4)
library(tableone)
library(stargazer)
library(psych)

options( digits=3 )
knitr::opts_chunk$set( fig.height=3 )
```

In this document we give a few simple plots and summary tables for exploring and describing data that may be useful for final projects and other things as well.
This includes a few simple model diagnostic plots to check for extreme outliers and whatnot.

It is a bit of a hodge-podge, but skimming to get some ideas is definitely worthwhile.



## National Youth Survey Example

Our running example is the National Youth Survey (NYS) data as described in Raudenbush and Bryk, page 190.
This data comes from a survey in which the same students were asked yearly about their acceptance of 9 "deviant" behaviors (such as smoking marijuana, stealing, etc.).
The study began in 1976, and followed two cohorts of children, starting at ages 11 and 14 respectively.
We will analyze the first 5 years of data.

At each time point, we have measures of:

-   `ATTIT`, the attitude towards deviance, with higher numbers implying higher tolerance for deviant behaviors.
-   `EXPO`, the "exposure", based on asking the children how many friends they had who had engaged in each of the "deviant" behaviors.

Both of these variables have been transformed to a logarithmic scale to reduce skew.

For each student, we have:

-   Gender (binary)
-   Minority status (binary)
-   Family income, in units of \$10K (this can be either categorical or continuous).

### Getting the data ready

We'll focus on the first cohort, from ages 11-15.
First, let's read the data.
Note that this data frame is in "wide format".
That is, there is only one row for each student, with all the different observations for that student in different columns of that one row.

```{r,  message=FALSE}
nyswide <- read_csv("data/nyswide.csv")
head(nyswide)
```

For our purposes, we want it in "long format", i.e. each student has multiple rows for the different observations.
The `pivot_longer()` command does this for us.

```{r}
nys1 <- nyswide |> 
  pivot_longer(ATTIT.11:EXPO.15, names_to = "score") |> 
  mutate(outcome = word(score, 1, 1, sep = "\\."),
         age = as.numeric(word(score, 2, 2, sep = "\\.")),
         age_fac = factor(age)) |> 
  select(-score) |> 
  pivot_wider(names_from = outcome) |> 
  # drop missing ATTIT values
  drop_na(ATTIT)

head( nys1 )
```

Just to get a sense of the data, let's plot each age as a boxplot

```{r, fig.height=3}
  ggplot(nys1, aes(age_fac, ATTIT)) +
    geom_boxplot() + 
    labs(title = "Boxplot of attitude towards deviance by age", 
         x = "Age", y = "Attitude towards deviance")
```

*Note:* The boxplot's "x" variable is the group.
You get one box per group.
The "y" variable is the data we are making boxplots of.

Note some features of the data:

-   First, we see that `ATTIT` goes up over time.
-   Second, we see the variation of points also goes up over time. This is evidence of heteroskedasticity.

If we plot individual lines we have:

```{r, fig.height = 3}
nys1 |> 
  drop_na() |> 
  ggplot(aes(age, ATTIT, group=ID)) +
    geom_line(alpha=0.2, position = "jitter") + 
    labs(title = "Individual trajectories of attitude towards deviance over time",
         x = "Age",
         y ="Attitude towards deviance")
```

Note how we have correlation of residuals: some students have systematically lower trajectories and some students have systematically higher trajectories (although there is a lot of bouncing around).

### Tabulating data (Categorical variables)

We can tabulate data as so:

```{r}
table(nys1$age)
```

or

```{r}
table(nys1$MINORITY, nys1$age)
```

Interestingly, we have more observations for later ages.

We can make "proportion tables" as well:

```{r}
prop.table( table( nys1$MINORITY, nys1$INCOME  ), margin=1 )
```

The margin determines what adds up to 100%.

### Summary stats (continuous variables)

The `tableone` package is useful:

```{r}
  library(tableone)
  
# sample mean  
  CreateTableOne(data = nys1,
                 vars = c("ATTIT"))
  
# you can also stratify by a variables of interest
  CreateTableOne(data = nys1,
                 vars = c("ATTIT"), 
                 strata = c("FEMALE"))
  
# you can also include binary variables
  CreateTableOne(data = nys1, 
                 vars = c("ATTIT", "age_fac"),  # include both binary and continuous variables here
                 factorVars = c("age_fac"), # include only binary variables here
                 strata = c("FEMALE"))
```


## Table of summary stats with `stargazer`

You can easily make pretty tables using the `stargazer` package, although there is a slight wrinkle in that it gets confused if you give it a "tibble" (from the tidyverse) instead of a "data.frame" (from base R).
So you have to "cast" your data to data.frames to make it work:

```{r, messages=FALSE}
  library(stargazer)
  
  # to include all variables
  stargazer( as.data.frame(nys1), header = FALSE, type="text")
```

You can include only some of the variables and omit stats that are not of interest:

```{r, messages=FALSE}
# to include only variables of interest
  stargazer( as.data.frame( nys1[2:7] ), header=FALSE, 
            omit.summary.stat = c("p25", "p75", "min", "max"), # to omit percentiles
            title = "Table 1: Descriptive statistics",
            type="text")

```

See the `stargazer` help file for how to set/change more of the options: https://cran.r-project.org/web/packages/stargazer/stargazer.pdf

To use `stargazer` in a PDF report, you would not set `type="text"` but rather `type="latex"` or `type="html"`, and then in the markdown chunk header (the thing that encloses all your R code) you would say "results='asis'".


### Descriptive Statistics with the `psych` Package

Another package for obtaining detailed descriptive statistics for your data is the `psych` package in R which has `describe()`, a function that generates a comprehensive summary of each variable in your dataset.

If you haven't already installed the `psych` package, you can do so using `install.packages()`.
You then load the library as so:

```{r}
# install.packages("psych")
library(psych)
```

The `describe()` function provides descriptive statistics such as mean, standard deviation, skewness, and kurtosis for each variable in your dataset.

Here's an example using a built-in dataset, `iris`:
```{r}
summary_stats <- describe(nys1)
print(summary_stats)
```

The `describe()` function generates a table with the following columns:

 - **vars**: The variable number.
 - **n**: Number of valid cases.
 - **mean**: The mean of the variable.
 - **sd**: The standard deviation.
 - **median**: The median of the variable.
 - **trimmed**: The mean after trimming 10% of the data from both ends.
 - **mad**: The median absolute deviation (a robust estimate of the variability).
 - **min**: The minimum value.
 - **max**: The maximum value.
 - **range**: The range (max - min).
 - **skew**: The skewness (measure of asymmetry).
 - **kurtosis**: The kurtosis (measure of peakedness).
 - **se**: The standard error.


### The `skimr` Package 

Another package that provides a comprehensive summary of your data is the `skimr` package.
It is more about exploring data in the moment than report generation, however.

One warning is `skimr` can generate special characters that can crash a R markdown report in some cases--so if you are using it, and getting weird errors when trying to render your reports, try commenting out the `skim()` call.
Using it is simple:

```{r}
skimr::skim( nys1 )
```



## High School and Beyond Example

For this part, we'll use the HSB data to illustrate summarizing variables by group (in our case, school).

```{r}
# load data 
dat <- read_dta("data/hsb.dta")
```

## Summarizing by group

To plot summaries by group, first aggregate your data, and plot the results.
Like so:

```{r}
aggdat = dat %>% 
  group_by(schoolid, sector) %>%
  summarize( per.fem = mean( female ) )

head( aggdat )
```

The including sector (a level 2 variable) is a way to ensure it gets carried through to the aggregated results.
Neat trick.

Anyway, we then plot:

```{r, fig.height=3}
qplot( aggdat$per.fem,
       main = "Percent female students", 
       xlab = "")
```

Note the single sex (catholic) schools.
We can facet to see both groups:

```{r, fig.height=3}
qplot( per.fem, data=aggdat,
       main = "Percent female students", 
       xlab = "") +
  facet_wrap( ~ sector )
```

## Diagnostic plots

We can also make some disagnostic plots for our model.
first, let's fit a random intercept model.

```{r}
m1 <- lmer(mathach ~ 1 + ses + (1|schoolid), data=dat)
arm::display(m1)
```

We can check if some of our assumptions are being grossly violated, i.e. residuals at all levels are normally distributed.

```{r}
  qplot(ranef(m1)$schoolid[,1],
       main = "Histogram of random intercepts", xlab="")

  qplot(resid(m1), 
       main = "Hisogram of residuals")
```

We can check for heteroskedasticity by plotting residuals against predicted values

```{r}
  dat$yhat  = predict(m1)
  dat$resid = resid(m1)
  
  ggplot(dat, aes(yhat, resid)) + 
      geom_point(alpha=0.3) + 
      geom_smooth() + 
      labs(title = "Residuals against predicted values",
           x = "Predicted values", y ="Residuals")
```

It looks reasonable (up to the discrete and bounded nature of our data).
No major weird curves in the loess line through the residuals means linearity is a reasonable assumption.
That being said, our nominal SEs around our loess line are tight, so the mild curve is probably evidence of *some* model misfit.

We can also look at the distribution of random effects using the `lattice` package

```{r}
  library(lattice)
  qqmath(ranef(m1, condVar=TRUE), strip=FALSE)
```
